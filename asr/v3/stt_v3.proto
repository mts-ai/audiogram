syntax = "proto3";

import "google/protobuf/empty.proto";

package mts.ai.audiogram.stt.v3;

//REQUEST CONFIG BEGIN

message FileRecognizeRequest {
  RecognitionConfig config = 1;
  bytes audio = 2;
}

message RecognizeRequest {
  oneof streaming_request {
    StreamRecognitionConfig config = 1;
    bytes audio = 2;
  }
}

message RecognitionConfig {
  enum VoiceActivityMarkEventsMode {
    VA_DISABLE = 0;
    VA_ENABLE = 1;
    VA_ENABLE_ASYNC = 2;
  }
  AudioEncoding encoding = 1;
  uint32 sample_rate_hertz = 2;
  string language_code = 3;
  uint32 audio_channel_count = 4;
  bool split_by_channel = 5;
  string model = 6;
  bool enable_word_time_offsets = 7;
  VoiceActivityConfig va_config = 8;
  VoiceActivityMarkEventsMode va_response_mode = 9;
  GenderAgeEmotionConfig genderage_config = 10;
  AntiSpoofingConfig antispoofing_config = 11;
  ContextDictionaryConfig context_dictionary = 12;
  PunctuationConfig punctuation_config = 13;
  DenormalizationConfig denormalization_config = 14;
  SpeakerLabelingConfig speaker_labeling_config = 15;
}

message StreamRecognitionConfig {
  RecognitionConfig config = 1;
  bool single_utterance = 2;
  bool interim_results = 3;
}

enum AudioEncoding {
  ENCODING_UNSPECIFIED = 0;
  LINEAR_PCM = 1;
  FLAC = 2;
  MULAW = 3;
  ALAW = 20;
}

message VoiceActivityConfig {
  enum VoiceActivityDetectionAlgorithmUsage {
    USE_VAD = 0;
    DO_NOT_PERFORM_VOICE_ACTIVITY = 1;
    USE_DEP = 2;
  }

  VoiceActivityDetectionAlgorithmUsage usage = 1;
  oneof algo_options {
    VADOptions vad_options = 2;
    DEPOptions dep_options = 3;
  }
}

message VADOptions {
  enum VoiceActivityDetectionMode {
    VAD_MODE_DEFAULT = 0;
    SPLIT_BY_PAUSES = 1;
    ONLY_SPEECH = 2;
  }
  float threshold = 1;
  int32 speech_pad_ms = 2;
  uint32 min_silence_ms = 3;
  uint32 min_speech_ms = 4;
  VoiceActivityDetectionMode mode = 5;
}

message DEPOptions {
  float smoothed_window_threshold = 1;
  int32 smoothed_window_ms = 2;
}

message GenderAgeEmotionConfig{
  bool enable = 1;
}

enum AttackType {
  LOGICAL = 0;
  PHYSICAL = 1;
  ALL_TYPES = 2;
}

message AntiSpoofingConfig {
  AttackType type = 1;
  oneof false_rate_type {
    float FAR = 2;
    float FRR = 3;
  }
  uint32 max_duration_for_analysis_ms = 4;
  bool enable = 5;
}

message ContextDictionaryConfig{
  string dictionary_name = 1;
  float weight = 2;
}

message PunctuationConfig {
  bool enable = 1;
}

message DenormalizationConfig {
  bool enable = 1;
}

message SpeakerLabelingConfig{
  bool enable = 1;
  oneof speakers{
    uint32 max_speakers = 2;
    uint32 num_speakers = 3;
  }
}
//REQUEST CONFIG END

//RESPONSE BEGIN
message FileRecognizeResponse{
  repeated RecognizeResponse response = 1;
}

message RecognizeResponse {
  SpeechRecognitionHypothesis hypothesis = 1;
  bool is_final = 2;
  int32 channel = 3;
  repeated VoiceActivityMark va_marks = 4;
  SpeakerGenderAgePrediction genderage = 5;
  repeated SpoofingResult spoofing_result = 6;
  SpeakerInfo speaker_info = 7;
}

message SpeechRecognitionHypothesis {
  message WordInfo {
    uint32 start_time_ms = 1;
    uint32 end_time_ms = 2;
    string word = 3;
    float confidence = 4;
  }
  string transcript = 1;
  string normalized_transcript = 2;
  float confidence = 3;
  uint32 start_time_ms = 4;
  uint32 end_time_ms = 5;
  repeated WordInfo words = 6;
  repeated WordInfo normalized_words = 7;
}

message VoiceActivityMark {
  enum VoiceActivityMarkType {
    VA_MARK_NONE = 0;
    VA_MARK_BEGIN = 1;
    VA_MARK_END = 2;
  }

  VoiceActivityMarkType mark_type = 1;
  uint32 offset_ms = 2;
}

message SpeakerGenderAgePrediction {
  message EmotionsRecognition {
    float positive = 1;
    float neutral = 2;
    float negative_angry = 3;
    float negative_sad = 4;
  }

  enum GenderClass {
    GENDER_UNDEF = 0;
    GENDER_MALE = 1;
    GENDER_FEMALE = 2;
  }

  enum AgeClass {
    AGE_UNDEF = 0;
    AGE_ADULT = 1;
    AGE_CHILD = 2;
  }

  GenderClass gender = 1;
  AgeClass age = 2;
  EmotionsRecognition emotion = 3;
}

message SpoofingResult {
  enum AttackResult {
    ATTACK_DETECTED = 0;
    GENUINE = 1;
  }
  AttackType type = 1;
  AttackResult result = 2;
  float confidence = 3;
  uint32 start_time_ms = 4;
  uint32 end_time_ms = 5;
}

message SpeakerInfo{
  uint32 speaker_id = 1;
}
//RESPONSE END

// MODELS INFO BEGIN
message ModelsInfo {
  repeated ModelInfo models = 1;
}

message ModelInfo {
  string name = 1;
  uint32 sample_rate_hertz = 2;
  string language_code = 3;
  repeated string dictionary_name = 4;
}
// MODELS INFO END

service STT {
  rpc FileRecognize(FileRecognizeRequest) returns (FileRecognizeResponse);
  rpc Recognize (stream RecognizeRequest) returns (stream RecognizeResponse);
  rpc GetModelsInfo(google.protobuf.Empty) returns (ModelsInfo);
}
