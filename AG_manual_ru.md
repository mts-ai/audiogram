
# О продукте

**Audiogram** – это сервис на базе нейронных сетей и методов машинного обучения для распознавания и синтеза речи. Audiogram позволяет выполнять:

* **Синхронное распознавание речи**. В этом случае сервис получает запрос с аудиофайлом, который необходимо расшифровать, и возвращает распознанный текст. Данный способ выполняется последовательно и считается наиболее точным. Подходит, например, для расшифровки телефонных разговоров.

* **Асинхронное (отложенное) распознавание речи**. Этот способ позволяет распознавать крупные аудиофайлы (размером до 1 ГБ) за период до 8 часов. Необходимо сохранить аудиофайл в s3-хранилище, а затем отправить в Audiogram запрос на отложенное распознавание, содержащий путь к аудиофайлу и параметры распознавания. Во время распознавания можно проверить статус или отменить задачу. Когда распознавание будет закончено, Audiogram сохранит результаты распознавания в s3 рядом с аудио.

* **Потоковое распознавание речи**. В случае потокового распознавания устанавливается соединение с Audiogram, по которому речь говорящего отправляется на распознавание частями в режиме online. Сервис возвращает результаты расшифровки по мере обработки. Данный способ подходит, например, для создания голосовых помощников или субтитров к видео.

* **Синхронный синтез речи**. При синхронном синтезе запрос к Audiogram содержит текст, который необходимо озвучить, и дополнительную информацию по голосу, частоте дискретизации и кодировке. В ответ возвращается аудиофайл с озвученным текстом. Этот способ может использоваться, например, для озвучивания книг.

* **Потоковый синтез речи**. При потоковом синтезе текст отправляется в Audiogram и озвучивается по частям. Потоковый синтез подходит, например, для создания ответных реплик голосовых помощников, так как позволяет достичь эффекта живого общения без неестественных пауз.

* **Сбор аудиоартефактов**. Аудиофайлы, поступающие в Audiogram на распознавание речи, сохраняются в отдельном хранилище и могут быть использованы для обучения и усовершенствования ML-моделей, отвечающих за расшифровку речи.

* **Управление клиентами и просмотр статистики**. Это можно сделать с помощью удобного веб-клиента в любом браузере.

# Термины в документе

* **Audiogram** (также **Продукт**, **Система**) – сервис, выполняющий услуги по распознаванию речи (превращению аудиозаписей с речью в текст) и синтезированию речи (озвучиванию текстов).

* **ASR** (**Automatic Speech Recognition**) – запрос на распознавание речи.

* **TTS** (**Text-to-Speech**) – запрос на синтезирование речи.

* **ML-модель** (также **нейросеть**, **искусственный интеллект**) – программа, обученная распознаванию определенных типов закономерностей, которая используется в Audiogram для автоматизации и ускорения выполнения запросов на синтез и распознавание речи. В Audiogram используются различные ML-модели (в зависимости от типа запроса и деталей запросов).

* **Бот** (также **чат-бот**, **электронный помощник**) – программа, отвечающая на запросы пользователей и имитирующая живое общение между людьми.

# Демонстрация Audiogram

Вы можете бесплатно попробовать отправить какой-нибудь текст на озвучку или аудиофайл на распознавание, используя демонстрационную форму Audiogram, которая доступна [на основной странице продукта](https://mts.ai/ru/product/audiogram/).

# Варианты поставки Audiogram

Возможны 2 варианта поставки Audiogram:

* **SaaS**: Audiogram установлен в облаке MTS AI. Доступ к сервису осуществляется через подключение по API (gRPC).

* **On-premise**: Audiogram развернут и функционирует в инфраструктуре заказчика.

# Справочник API

## Синхронное распознавание речи

Распознавание речи - это процесс преобразования аудио в текст. Синхронное распознавание речи работает следующим образом - вы отправляете в Audiogram запрос с аудио, речь из которого необходимо распознать, а в ответ получаете результаты распознавания.

Синхронное распознавание бывает 2 видов:

* **потоковое**: В этом случае между клиентским приложением и Audiogram устанавливается соединение. Речь поступает на распознавание частями (чанками), по мере записи аудиосигнала. Audiogram выполняет и возвращает результаты распознавания также по частям. Чаще всего потоковое распознавание используется для создания голосовых помощников.
<br>

* **файловое синхронное**: клиентское приложение отправляет в Audiogram запрос с файлом, речь из которого надо распознать. Audiogram выполняет распознавание и возвращает результат в ответе на запрос. Файловое синхронное распознавание используют, когда необходимо транскрибировать речь из небольших аудиофайлов, записанных заранее.
<br>

Для работы с Audiogram Заказчикам предлагается gRPC контракт (proto-файлы), который можно использовать, например, для создания собственного клиентского приложения.

**Важно!** Есть 2 вида gRPC контрактов:

1. **Через полную конфигурацию запроса**: позволяет самостоятельно настраивать все параметры распознавания речи.
<br>

2. **Через пресеты**: под Заказчика заранее создается конфигурация распознавания речи (**пресет**), которая скрывает все настройки. Этот вид контракта позволяет пользователям избежать непреднамеренных ошибок конфигурации.

В следующих секциях подробнее рассмотрим эти контракты.

### Через полную конфигурацию запроса

Для создания клиентского приложения, которое будет отправлять в Audiogram запросы на распознавание речи через полную конфигурацию настроек, вам понадобятся следующие .proto-файлы:

<u>Основной контракт</u>:

* [stt_v3.proto](https://github.com/mts-ai/audiogram/blob/main/asr/asr/full_config/v3/stt_v3.proto) - основной контракт, по которому происходит распознавание речи.

<u>Зависимости</u>:

* [stt_response.proto](https://github.com/mts-ai/audiogram/blob/main/asr/asr/full_config/v3/stt_response.proto) - конфигурация ответа на запрос на распознавание речи.
* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/asr/asr/full_config/v3/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки.

**Примечание 1**: Для создания собственного клиентского приложения можно использовать любой язык программирования, который есть в библиотеке для работы с gRPC. Подробную информацию об этом протоколе можно посмотреть на [https://grpc.io](https://grpc.io)

**Примечание 2**: Максимальная длина сообщения, принимаемого от клиентских приложений по gRPC (в байтах): 62914560 

#### stt_v3.proto

##### Методы

###### FileRecognize

Выполняет распознавание речи в файловом режиме.

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| FileRecognize | FileRecognizeRequest | mts.ai.audiogram.stt_response.v1.FileRecognizeResponse | Метод распознавания аудиофайла целиком. Ожидает аудиофайл, в этом же соединении возвращает результат и закрывает соединение. |

###### Recognize

Выполняет распознавание речи в потоковом режиме.

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| Recognize | stream RecognizeRequest | stream mts.ai.audiogram.stt_response.v1.RecognizeResponse | Этот метод позволяет проводить распознавание речи в потоковом режиме. Клиент устанавливает соединение с Audiogram и отправляет аудио на распознавание по кускам (чанками). Рекомендуется делать длительность чанка от 250 до 500 миллисекунд (мс). Распознавание проходит по мере поступления аудиоданных и заканчивается, когда поток закрывается клиентом. |

###### GetModelsInfo

Запрашивает список моделей для распознавания речи.

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| GetModelsInfo | google.protobuf.Empty | ModelsInfo | Метод запроса списка моделей для распознавания речи. Ничего не принимает в качестве аргументов, возвращает список доступных моделей. |

##### Сообщения PROTOBUF

###### FileRecognizeRequest

Запрос на распознавание аудио в файловом режиме.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| config | RecognitionConfig | Конфигурация распознавания. |
| audio | bytes | Аудио для распознавания. |

###### RecognizeRequest

Запрос на распознавание аудио в потоковом режиме.

Первое сообщение типа RecognizeRequest должно содержать данные в поле «config» и не должно содержать данные в поле «audio». Все последующие сообщения RecognizeRequest, наоборот, не должны иметь данных в поле «config», а в поле «audio» передаются аудиоданные. Аудиобайты должны быть закодированы, как указано в RecognitionConfig.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| config | StreamRecognitionConfig | Конфигурация распознания. |
| audio | bytes | Аудиофрагменты для распознания. При распознавании речи в потоковом режиме Audiogram принимает аудио по кускам (чанками). Рекомендуется делать чанки длительностью от 250 до 500 миллисекунд. |

###### RecognitionConfig

Конфигурация распознавания при вызове метода FileRecognize.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| encoding | enum AudioEncoding | Формат аудиоданных (кодировка). |
| sample_rate_hertz | uint32 | Частота дискретизации аудиоданных в герцах. |
| language_code | string | Язык, используемый в аудиофайле. |
| audio_channel_count | uint32 | Количество каналов во входных аудиоданных. |
| split_by_channel | bool | Этот флаг работает только для распознавания в файловом режиме. При его включении каждый канал будет распознаваться отдельно. Может применяться, например, для аудио из колл-центров, где в одном канале голос клиента, а в другом - оператора. |
| model | string | Модель распознавания. |
| enable_word_time_offsets | bool | Флаг, включающий вывод временных меток слов (которые возвращаются в поле word структуры WordInfo).<br> <li>при значении «true» результат включает временные метки для этих слов;<br> <li>при значении «false» информация о временных метках не возвращается. |
| va_config | VoiceActivityConfig | Конфигурация Voice Activity. |
| va_response_mode | VoiceActivityMarkEventsMode | Режим отправки разметки клиенту. По умолчанию – VA_DISABLE. |
| genderage_config | GenderAgeEmotionConfig | Конфигурация модели по определению пола, возраста и эмоционального настроя говорящего. |
| antispoofing_config | AntiSpoofingConfig | Конфигурация антиспуфинга. |
| context_dictionary | ContextDictionaryConfig | Конфигурация распознавания речи с участием словаря. |
| punctuation_config | PunctuationConfig | Конфигурация модели проставления пунктуации. |
| denormalization_config | DenormalizationConfig | Конфигурация модели денормализации чисел (перевод текстового представления числа в цифровую, например, "пять объектов > 5 объектов"). |
| speaker_labeling_config | SpeakerLabelingConfig | Конфигурация диаризации (определение принадлежности распознаваемых фраз к определенным спикерам и разделение аудио на сегменты, относящиеся к определенным спикерам) |

###### VoiceActivityMarkEventsMode

Режим отправки разметки VoiceActivity клиенту.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| VA_DISABLE | 0 | Отключает отправку отметок VoiceActivityMark. |
| VA_ENABLE | 1 | Включает отправку отметок VoiceActivityMark синхронно вместе с транскрипцией. |
| VA_ENABLE_ASYNC | 2 | Включает отправку отметок VoiceActivityMark асинхронно (как только будет получена разметка, не дожидаясь работы asr). Для файлового режима работает идентично ENABLE. |

###### StreamRecognitionConfig

Конфигурация распознавания при вызове метода Recognize.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| config | RecognitionConfig | Конфигурация распознавания. |
| single_utterance | bool | Флаг для включения режима распознавания одной фразы. В этом режиме (при выставленном значении «true») распознавание завершается сервисом сразу после распознавания первой фразы и соединение разрывается. |
| interim_results | bool | Конфигурация для промежуточных результатов:<br> <li>при значении «true» возвращаются промежуточные результаты (промежуточные гипотезы) и конечные результаты;<br> <li>при значении «false» возвращаются только конечные результаты (у которых is_final = true). |

###### AudioEncoding

Поддерживаемые форматы аудиоданных.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| ENCODING_UNSPECIFIED | 0 | На текущий момент не поддерживается. |
| LINEAR_PCM | 1 | PCM без заголовков с целыми знаковыми 16-битными сэмплами в линейном распределении (PCM 16bit). |
| FLAC | 2 | На текущий момент не поддерживается. |
| MULAW | 3 | PCM без заголовков с 8-битными сэмплами в формате mu-law. |
| ALAW | 20 | PCM без заголовков с 8-битными сэмплами в формате a-law. |

###### VoiceActivityConfig

Структура данных для хранения всех настроек VoiceActivity.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| usage | VoiceActivityDetectionAlgorithmUsage | Выбор алгоритма VoiceActivity. При DO_NOT_PERFORM_VOICE_ACTIVITY разметка аудио выключена. Значение по умолчанию - USE_VAD |
| vad_options | VADOptions | Опции алгоритма VAD. Используется при VoiceActivityDetectionAlgorithmUsage = USE_VAD |
| dep_options | DEPOptions | Опции алгоритма DEP. Используется при VoiceActivityDetectionAlgorithmUsage = USE_DEP |
| enhanced_vad_options | EnhancedVADOptions | Сообщение типа EnhancedVADOptions |
| target_speech_vad_options | TargetSpeechVADOptions | Сообщение типа TargetSpeechVADOptions |

###### VoiceActivityDetectionAlgorithmUsage

Тип используемого алгоритма VoiceActivity.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| <span id="VAD">USE_VAD</span> | 0 | Включает использование VAD-алгоритма (Voice Activity Detection) для разбиения на фразы. Этот алгоритм определяет окончание фразы по паузам в речи и тишине. |
| <span id="NOACT">DO_NOT_PERFORM_VOICE_ACTIVITY</span> | 1 | Отключает разбиение на фразы по Voice Activity. То есть весь распознанный текст будет получен в виде одной фразы. |
| <span id="DEP">USE_DEP</span> | 2 | Включает использование DEP-алгоритма для разбиения на фразы. Этот алгоритм реализует более сложную логику определения окончания фразы по законченности мысли. Подходит для создания голосовых ботов. |
| USE_ENHANCED_VAD | 3 | Включает улучшенную и более современную версию алгоритма VAD, который разбивает аудиопоток на фразы. Универсально подходит для всех типов задач. |
| USE_TARGET_SPEECH_VAD | 4 | Включает использование алгоритма Target Speech VAD. Он основан на алгоритме Enhanced VAD, но отличается тем, что научен работать в шумной среде, где выделяет речь только основного спикера. Может не услышать тихую или неразборчивую речь. |

###### VADOptions

Настройки работы алгоритма VAD.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| threshold | float | Порог срабатывания VAD. Если вероятность речи выше порога, значит обработанный чанк содержит речь. Возможные значения: (0, 1.0). Значение по умолчанию для распознавания в файловом режиме - 0.1. Значение по умолчанию для распознавания в потоковом режиме - 0.9 |
| speech_pad_ms | int32 | Отступ, добавляемый к границам найденных фрагментов (если speech_pad_ms < 0, отступ будет "внутрь" фрагмента). Опция применима только для распознавания речи в файловом режиме (для FileRecognize запросов). Единицы измерения - миллисекунды. Значение по умолчанию - 300 |
| min_silence_ms | uint32 | Если между двумя фрагментами речи встречается пауза короче min_silence_ms, то такая пауза не учитывается и фрагменты объединяются в один. Единицы измерения - миллисекунды. Возможные значения: min_silence_ms >= 0. Значение по умолчанию - 1000 мс |
| min_speech_ms | uint32 | Минимальная продолжительность речи. Фрагменты короче min_speech_ms не учитываются. Опция применима только для распознавания речи в файловом режиме (для FileRecognize запросов). Единицы измерения - миллисекунды. Возможные значения: min_speech_ms >= 0. Значение по умолчанию - 250 |
| mode | VoiceActivityDetectionMode | Выбор типа разметки VAD-ом аудиофайла для запроса в файловом режиме. |

###### VoiceActivityDetectionMode

Выбор типа разметки аудио с помощью VAD.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| VAD_MODE_DEFAULT | 0 | Значение по умолчанию для распознавания в файловом режиме - SPLIT_BY_PAUSES, для распознавания в потоковом режиме - ONLY_SPEECH. |
| SPLIT_BY_PAUSES | 1 | Аудио разделяется по паузам (ничего не вырезается). |
| ONLY_SPEECH | 2 | Вырезаются только сегменты с речью. |

###### DEPOptions

Настройки работы алгоритма DEP.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| smoothed_window_threshold | float | Порог срабатывания алгоритма DEP. На заданном окне сглаживания считается среднее значение верояности завершения фразы. Если это значение больше порога то алгоритм срабатывает. Возможные значения: (0, 1.0). Значение по умолчанию - 0.754 |
| smoothed_window_ms | int32 | Окно, на котором происходит сглаживание при принятии решения о конце фразы. Единицы измерения - миллисекунды. Возможные значения: smoothed_window_ms >= 10. Значение по умолчанию - 970 мс. Значение должно быть кратно 10 мс |

###### EnhancedVADOptions

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| beginning_window_ms | int32 | Размер окна (в миллисекундах), для сглаживания вероятности наличия речи в каждый момент времени. Для каждого момента времени вероятность наличия речи считается как средняя вероятность за предыдущее окно размером beginning_window_ms. Размер окна не должен превышать размер чанка и должен быть кратен 40мс. Используется для поиска границы начала речи. |
| beginning_threshold | float | Порог срабатывания модели для поиска начала речи. Используется для поиска начала фразы. Если в текущий момент вероятность речи превысила порог beginning_threshold, то считается, что обнаружено начало речи. Значение порога - от 0 до 1. |
| ending_window_ms | int32 | Размер окна (в миллисекундах), для сглаживания вероятности наличия речи в каждый момент времени. Для каждого момента времени вероятность наличия речи считается как средняя вероятность за "будущее" окно (в пределах чанка) размером ending_window_ms. Размер окна не должен превышать размер чанка и должен быть кратен 40мс. Используется для поиска границы конца речи. |
| ending_threshold | float | Порог срабатывания модели для поиска конца речи. Используется для поиска конца фразы. Если ранее было обнаружено начало речи, то конец речи наступает в момент, когда вероятность наличия речи становится ниже порога ending_threshold. Значение порога - от 0 до 1. Должно быть меньше, чем beginning_threshold. |

###### TargetSpeechVADOptions

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| beginning_window_ms | int32 | Размер окна (в миллисекундах), для сглаживания вероятности наличия речи в каждый момент времени. Для каждого момента времени вероятность наличия речи считается как средняя вероятность за предыдущее окно размером beginning_window_ms. Размер окна не должен превышать размер чанка и должен быть кратен 40мс. Используется для поиска границы начала речи. |
| beginning_threshold | float | Порог срабатывания модели для поиска начала речи. Используется для поиска начала фразы. Если в текущий момент вероятность речи превысила порог beginning_threshold, то считается, что обнаружено начало речи. Значение порога - от 0 до 1. |
| ending_window_ms | int32 | Размер окна (в миллисекундах), для сглаживания вероятности наличия речи в каждый момент времени. Для каждого момента времени вероятность наличия речи считается как средняя вероятность за "будущее" окно (в пределах чанка) размером ending_window_ms. Размер окна не должен превышать размер чанка и должен быть кратен 40мс. Используется для поиска границы конца речи. |
| ending_threshold | float | Порог срабатывания модели для поиска конца речи. Используется для поиска конца фразы. Если ранее было обнаружено начало речи, то конец речи наступает в момент, когда вероятность наличия речи становится ниже порога ending_threshold. Значение порога - от 0 до 1. Должно быть меньше, чем beginning_threshold. |

###### GenderAgeEmotionConfig

Настройки работы сервиса genderage.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| enable | bool | Флаг, включающий модуль определения пола, возраста и эмоционального настроя говорящего. Примечание: пол ребенка в настоящий момент не определяется. |

###### AntiSpoofingConfig

Конфигурация антиспуфинга.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| FAR | float | Допустимый процент принятия ботов за людей. |
| FRR | float | Допустимый процент отклонения людей (принятия их за ботов). |
| max_duration_for_analysis_ms | uint32 | Максимальная длительность анализа (в миллисекундах). Значение по умолчанию - 5000 миллисекунд. |
| enable | bool | Флаг, включающий модуль определения является ли аудио, поступившее на распознавание, спуфинг-атакой. |

###### ContextDictionaryConfig

Конфигурация распознавания речи с участием словаря.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| dictionary_name | string | Название словаря. |
| weight | float | Вес указанного словаря в процессе распознавания. |

###### PunctuationConfig

Конфигурация модели капитализации и расстановки знаков препинания.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| enable | bool | Флаг, включающий модуль капитализации и расстановки знаков препинания. |

###### DenormalizationConfig

Конфигурация модели денормализации чисел.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| enable | bool | Флаг, включающий модуль денормализации чисел. |

###### SpeakerLabelingConfig

Конфигурация диаризации.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| enable | bool | Флаг, включающий модуль диаризации. |
| max_speakers | uint32 | Максимальное количество спикеров в аудио. Не является обязательным параметром, но улучшает качество диаризации. Этот параметр рекомендуется передать, если вы не знаете точное количество спикеров в аудио, но точно знаете, что их не больше определенного числа. |
| num_speakers | uint32 | Точное количество спикеров в аудио. Не является обязательным параметром, но улучшает качество диаризации. |

###### ModelsInfo

Доступные модели распознавания речи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| models | repeated ModelInfo | Список доступных моделей. |
| header | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### ModelInfo

Информация о модели распознавания речи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| name | string | Название модели распознавания речи. |
| sample_rate_hertz | uint32 | Частота дискретизации аудиоданных, с которой модель работает без необходимости перекодировать аудио. |
| language_code | string | Язык, речь на котором может распознавать модель, по умолчанию ru. |
| dictionary_name | repeated string | Название словаря (одного или нескольких), который используется моделью распознавания. |

#### stt_response.proto

##### Сообщения PROTOBUF

###### FileRecognizeResponse

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| response | repeated RecognizeResponse | Результат распознавания. |
| header | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### RecognizeResponse

Ответ с результатами распознавания для метода Recognize.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| hypothesis | SpeechRecognitionHypothesis | Результат распознавания речи. |
| is_final | bool | Флаг, указывающий, что сформирована окончательная гипотеза и меняться она больше не будет:<br> <li> «true», если пришла финальная гипотеза;<br> <li> «false» для промежуточных гипотез. |
| channel | int32 | Идентификатор канала (в настоящее время данный параметр не поддерживается). |
| va_marks | repeated VoiceActivityMark | Voice Activity разметка. Массив меток отправляется только если VoiceActivityMarkEventsMode = VA_ENABLE / VA_ENABLE_ASYNC. При VoiceActivityMarkEventsMode = VA_ENABLE_ASYNC все остальные поля структуры SpeechRecognitionResult могут быть пустые. |
| genderage | SpeakerGenderAgePrediction | Результат работы модели классификации мужчина/женщина/ребенок. Включается флагом enable в GenderAgeEmotionConfig. |
| spoofing_result | repeated SpoofingResult | Результат работы модели антиспуфинга. Включается флагом enable в AntiSpoofingConfig. |
| speaker_info | SpeakerInfo | Информация по спикеру, которому принадлежат распознанные фразы. |
| header | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### SpeechRecognitionHypothesis

Результат распознавания речи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| transcript | string | Результат работы модели распознавания речи без его последующей обработки сервисами денормализации чисел и расстановки знаков препинания. |
| normalized_transcript | string | Результат работы модели распознавания речи с его последующей обработкой сервисами денормализации чисел и расстановки знаков препинания. |
| confidence | float | Коэффициент достоверности (степень уверенности) распознанных фраз. |
| start_time_ms | uint32 | Временная метка начала распознанной фразы относительно начала аудиопотока. |
| end_time_ms | uint32 | Временная метка конца распознанной фразы относительно начала аудиопотока. |
| words | repeated WordInfo | Результат распознавания речи с разбивкой по словам. |
| normalized_words | repeated WordInfo | В настоящее время не поддерживается. |

###### WordInfo

Объект, содержащий информацию, относящуюся к распознанному слову.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| start_time_ms | uint32 | Временная метка начала слова относительно начала аудиопотока. |
| end_time_ms | uint32 | Временная метка конца слова относительно начала аудиопотока. |
| <span id="WORD">word</span> | string | Распознанное слово. |
| confidence | float | Коэффициент достоверности (степень уверенности) распознанного слова. |

###### VoiceActivityMark

Определяет разметку голосовой активности во входном акустическом сигнале. Сообщение включает в себя метку времени и тип метки.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| mark_type | VoiceActivityMarkType | Тип разметки. |
| offset_ms | uint32 | Метка времени с точкой отсчета начала входного акустического сигнала, единицы измерения - миллисекунды. |

###### VoiceActivityMarkType

Определяет тип метки голосовой активности.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| VA_MARK_NONE | 0 | Тип метки отсутствия изменения голосовой активности. |
| VA_MARK_BEGIN | 1 | Тип метки начала голосовой активности. |
| VA_MARK_END | 2 | Тип метки конца голосовой активности. |

###### SpeakerGenderAgePrediction

Пол, возраст и эмоциональная окраска голоса спикера.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| gender | GenderClass | Значение, определяющее пол. |
| age | AgeClass | Значение, определяющее возраст. |
| emotion | EmotionsRecognition | Значение, определяющее эмоциональную окраску голоса спикера. |

###### EmotionsRecognition

Эмоциональная окраска голоса спикера.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| positive | float | Положительный тон. |
| neutral | float | Нейтральный тон. |
| negative_angry | float | Сердитый тон. |
| negative_sad | float | Печальный тон (в данный момент этот параметр не поддерживается). |

###### GenderClass

Пол говорящего.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| GENDER_UNDEF | 0 | Пол не определен. |
| GENDER_MALE | 1 | Мужчина. |
| GENDER_FEMALE | 2 | Женщина. |

###### AgeClass

Возраст говорящего.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| AGE_UNDEF | 0 | Возраст не определен. |
| AGE_ADULT | 1 | Взрослый. |
| AGE_CHILD | 2 | Ребенок. |

###### SpoofingResult

Результат работы модели, определяющей является ли аудио, поступившее на распознавание, спуфинг-атакой.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| result | AttackResult | Результат определения является ли звонок спуфинг-атакой. |
| confidence | float | Уверенность в принятом решении в поле result. |
| start_time_ms | uint32 | Начальная метка временного отрезка, который анализировался на предмет спуфинг-атаки. |
| end_time_ms | uint64 | Конечная метка временного отрезка, который анализировался на предмет спуфинг-атаки. |

###### AttackResult

Информация - является ли аудио, поступившее на распознавание, спуфинг-атакой или голос принадлежит человеку.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| ATTACK_DETECTED | 0 | Зафиксирована спуфинг-атака (бот пытается выдать себя за человека). |
| GENUINE | 1 | Голос принадлежит человеку. |

###### SpeakerInfo

Информация по спикеру, которому принадлежат распознанные фразы.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| speaker_id | uint32 | Идентификатор (ID) спикера, которому принадлежат распознанные фразы. |

#### response_header.proto

##### Сообщения PROTOBUF

###### ResponseHeader

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| timestamp | uint64 | Время отправки ответа на стороне Audiogram. Позволяет высчитать сетевую задержку. |

### Через пресеты

Для создания клиентского приложения, которое будет отправлять в Audiogram запросы на распознавание речи через пресеты (заранее созданные под Заказчика конфигурации настроек запроса), вам понадобятся следующие .proto-файлы:

<u>Основной контракт</u>:

* [stt_presets.proto](https://github.com/mts-ai/audiogram/blob/main/asr/asr/presets/v1/stt_presets.proto) - основной контракт, по которому происходит распознавание речи.

<u>Зависимости</u>:

* [stt_response.proto](https://github.com/mts-ai/audiogram/blob/main/asr/asr/presets/v1/stt_response.proto) - конфигурация ответа на запрос на распознавание речи. Описание этого .proto-файла представлено [в секции stt_response.proto](#stt_responseproto)
* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/asr/asr/presets/v1/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки. Описание этого .proto-файла представлено [в секции response_header.proto](#response_headerproto)

**Примечание 1**: Для создания собственного клиентского приложения можно использовать любой язык программирования, который есть в библиотеке для работы с gRPC. Подробную информацию об этом протоколе можно посмотреть на [https://grpc.io](https://grpc.io)

**Примечание 2**: Максимальная длина сообщения, принимаемого от клиентских приложений по gRPC (в байтах): 62914560 

#### stt_presets.proto

##### Методы

###### FileRecognize

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| FileRecognize | FileRecognizeRequest | mts.ai.audiogram.stt_response.v1.FileRecognizeResponse | Выполняет распознавание речи в файловом режиме (синхронном). |

###### Recognize

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| Recognize | stream RecognizeRequest | stream mts.ai.audiogram.stt_response.v1.RecognizeResponse | Выполняет распознавание речи в потоковом режиме. |

##### Сообщения PROTOBUF

###### Preset

Эта структура содержит информацию о пресете настроек, который необходимо использовать для распознавания речи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| preset_name | string | Название пресета. |
| preset_version | int32 | Версия пресета. |

Название и версию пресета, который вам надо использовать, можно получить у менеджеров Audiogram.

###### FileRecognizeRequest

Конфигурация файлового (синхронного) распознавания.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| preset | Preset | Сообщение типа Preset (описано выше). |
| audio | bytes | В это поле надо передать байты аудио, речь из которого необходимо распознать. |

###### RecognizeRequest

Конфигурация потокового распознавания.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| preset | Preset | Сообщение типа Preset (описано выше). |
| audio | bytes | В это поле надо передать чанки (байты аудио), речь из которого необходимо распознать. |

## Асинхронное (отложенное) распознавание речи

Распознавание речи - это процесс преобразования аудио в текст. Асинхронное (или отложенное) распознавание позволяет распознать речь из больших аудиофайлов (объемом до 1 ГБ). Чем больше размер аудио, тем дольше займет распознавание (до 8 часов).

Асинхронное распознавание работает следующим образом:

1. Клиент сохраняет аудиофайл (можно несколько, но объем каждого не должен превышать 1 ГБ) в хранилище (например, S3), которое используется Audiogram.
<br>

2. Далее, через gRPC API, необходимо поставить Audiogram задачу на асинхронное распознавание. В задаче указывается путь до аудиофайла и ряд других параметров (они описаны в следующих секциях).
<br>

3. По истечении некоторого времени, через клиентское приложение необходимо отправить в Audiogram запрос на получение статуса поставленной задачи.
<br>

4. Если задача выполнена, можно скачать результаты распознавания. Это делается через HTTP API сервиса audio-archive-back, который входит в состав Audiogram.
Результаты асинхронного распознавания сохраняются в хранилище рядом с исходными аудиофайлами.

Для работы с асинхронным распознаванием Заказчикам предлагается gRPC контракт (proto-файлы), который можно использовать, например, для создания собственного клиентского приложения.

**Важно!** Есть 2 вида gRPC контрактов:

1. **Через полную конфигурацию запроса**: позволяет самостоятельно настраивать все параметры распознавания речи.
<br>

2. **Через пресеты**: под Заказчика заранее создается конфигурация распознавания речи (**пресет**), которая скрывает все настройки. Этот вид контракта позволяет пользователям избежать непреднамеренных ошибок конфигурации.

В следующих секциях подробнее рассмотрим эти контракты.

### Через полную конфигурацию запроса

Для создания клиентского приложения, которое будет отправлять в Audiogram запросы на асинхронное распознавание речи через полную конфигурацию настроек, вам понадобятся следующие .proto-файлы:

<u>Основной контракт</u>:

* [longrunning_stt.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/full_config/v1/longrunning_stt.proto) - основной контракт, по которому происходит асинхронное распознавание речи.

<u>Зависимости</u>:

* [stt_v3.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/full_config/v1/stt_v3.proto) - полная конфигурация настроек распознавания речи. Описание этого .proto-файла представлено [в секции stt_v3.proto](#stt_v3proto)

* [stt_response.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/full_config/v1/stt_response.proto) - конфигурация ответа на запрос на распознавание речи. Описание этого .proto-файла представлено [в секции stt_response.proto](#stt_responseproto)

* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/full_config/v1/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки. Описание этого .proto-файла представлено [в секции response_header.proto](#response_headerproto)

* [longrunning_task.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/full_config/v1/longrunning_task.proto) - конфигурация задачи на асинхронное распознавание.

**Примечание 1**: Для создания собственного клиентского приложения можно использовать любой язык программирования, который есть в библиотеке для работы с gRPC. Подробную информацию об этом протоколе можно посмотреть на [https://grpc.io](https://grpc.io)

**Примечание 2**: Максимальная длина сообщения, принимаемого от клиентских приложений по gRPC (в байтах): 62914560 

#### longrunning_stt.proto

##### Методы

###### LongRunningRecognize

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| LongRunningRecognize | LongRunningRecognizeRequest | mts.ai.audiogram.longrunning_task.v1.Task | Создает задачу на распознавание речи в файловом (асинхронном) режиме. |

###### GetTaskInfo

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| GetTaskInfo | mts.ai.audiogram.longrunning_task.v1.TaskRequest | mts.ai.audiogram.longrunning_task.v1.Task | Получает информацию по задаче на распознавание речи в асинхронном режиме. |

###### CancelTask

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| CancelTask | mts.ai.audiogram.longrunning_task.v1.TaskRequest | mts.ai.audiogram.longrunning_task.v1.Task | Отменяет задачу на распознавание речи в асинхронном режиме. **Примечание**: нельзя отменить задачу, которая находится в статусе IN_PROGRESS. |

##### Сообщения PROTOBUF

###### LongRunningRecognizeRequest

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| config | mts.ai.audiogram.stt.v3.RecognitionConfig | Конфигурация запроса на распознавание речи. |
| s3_audio_path | repeated AudioPath | Это поле содержит один или несколько путей к аудиофайлам, которые надо распознать. |

###### AudioPath

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| bucket_name | string | Имя s3-контейнера (бакета), в котором хранится аудио, речь из которого необходимо распознать. |
| object_name | string | Имя объекта (аудиофайла), речь из которого необходимо распознать. |

#### longrunning_task.proto

##### Сообщения PROTOBUF

###### Task

Эта структура содержит информацию о поставленной задаче на асинхронное распознавание речи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| id | string | Идентификатор задачи. |
| status | Status | Статус задачи. |
| created_at | google.protobuf.Timestamp | Время создания задачи. |
| audio_requests | repeated Audio | Информация об аудиофайлах, которые будут распознаны в рамках задачи. |
| header | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### Status

Статус задачи на асинхронное распознавание речи.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| UNDEFINED | 0 | Статус не определен. |
| NEW | 1 | Новая задача. |
| IN_PROGRESS | 2 | Задача в процессе. |
| COMPLETE | 3 | Задача выполнена. |
| CANCELED | 4 | Задача отменена. |
| ERROR | 5 | Во время выполнения задачи произошла ошибка. |

###### Audio

Информация об аудиофайлах, которые будут распознаны в рамках задачи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| bucket_name | string | Имя s3-контейнера (бакета), в котором хранится аудиофайл, речь из которого необходимо распознать. |
| object_name | string | Имя объекта (аудиофайл), речь из которого необходимо распознать. |
| status | string | Статус задачи на распознавание речи. |
| response_id | string | Идентификатор, который приписывается распознаванию аудиофайла. По нему можно будет скачать результаты распознавания. |

###### TaskRequest

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| task_id | string | Идентификатор задачи на распознавание речи. Это то же самое, что и id в структуре Task. Только id возвращается в ответ на создание задачи. А затем, если необходимо посмотреть статус этой задачи или отменить ее, нужно вложить значение id в task_id и в запросах на статус или отмену указывать task_id. |

### Через пресеты

Для создания клиентского приложения, которое будет отправлять в Audiogram запросы на асинхронное распознавание речи через пресеты (заранее созданные под Заказчика конфигурации настроек запроса), вам понадобятся следующие .proto-файлы:

<u>Основной контракт</u>:

* [longrunning_presets.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/presets/v1/longrunning_presets.proto) - основной контракт, по которому происходит асинхронное распознавание речи через пресеты.

<u>Зависимости</u>:

* [stt_presets.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/presets/v1/stt_presets.proto) - контракт, по которому происходит распознавание речи через пресеты. Описание этого .proto-файла представлено [в секции stt_presets.proto](#stt_presetsproto)

* [longrunning_task.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/presets/v1/longrunning_task.proto) - конфигурация задачи на асинхронное распознавание. Описание этого .proto-файла представлено [в секции longrunning_task.proto](#longrunning_taskproto)

* [stt_response.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/presets/v1/stt_response.proto) - конфигурация ответа на запрос на распознавание речи. Описание этого .proto-файла представлено [в секции stt_response.proto](#stt_responseproto)

* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/asr/longrunning_asr/presets/v1/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки. Описание этого .proto-файла представлено [в секции response_header.proto](#response_headerproto)

**Примечание 1**: Для создания собственного клиентского приложения можно использовать любой язык программирования, который есть в библиотеке для работы с gRPC. Подробную информацию об этом протоколе можно посмотреть на [https://grpc.io](https://grpc.io)

**Примечание 2**: Максимальная длина сообщения, принимаемого от клиентских приложений по gRPC (в байтах): 62914560

#### longrunning_presets.proto

##### Методы

###### LongRunningRecognize

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| LongRunningRecognize | LongRunningRecognizeRequest | mts.ai.audiogram.longrunning_task.v1.Task | Создает задачу на распознавание речи в файловом (асинхронном) режиме. |

###### GetTaskInfo

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| GetTaskInfo | mts.ai.audiogram.longrunning_task.v1.TaskRequest | mts.ai.audiogram.longrunning_task.v1.Task | Получает информацию по задаче на распознавание речи в асинхронном режиме. |

###### CancelTask

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| CancelTask | mts.ai.audiogram.longrunning_task.v1.TaskRequest | mts.ai.audiogram.longrunning_task.v1.Task | Отменяет задачу на распознавание речи в асинхронном режиме. **Примечание**: нельзя отменить задачу, которая находится в статусе IN_PROGRESS. |

##### Сообщения PROTOBUF

###### LongRunningRecognizeRequest

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| preset | mts.ai.audiogram.stt_presets.v2.Preset | Описание пресета, который необходимо использовать. |
| s3_audio_path | repeated AudioPath | Это поле содержит один или несколько путей к аудиофайлам, которые надо распознать. |

###### AudioPath

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| bucket_name | string | Имя s3-контейнера (бакета), в котором хранится аудио, речь из которого необходимо распознать. |
| object_name | string | Имя объекта (аудиофайла), речь из которого необходимо распознать. |

## Синтез речи

Синтез речи - это процесс преобразования текста в голос. Вы отправляете в Audiogram запрос с текстом, который необходимо озвучить, и дополнительные настройки (каким голосом, с какой интонацией и т. д.). Audiogram выполняет озвучку и в ответе возвращает получившийся аудиофайл.

Синтез речи бывает 2 видов:

* **потоковый**: В этом случае текст отправляется в Audiogram и озвучивается частями по мере поступления. Потоковый синтез подходит, например, для создания ответных реплик голосовых помощников, так как позволяет достичь эффекта живого общения без неестественных пауз.
<br>

* **файловый**: При файловом синтезе весь текст, который необходимо озвучить, поступает в Audiogram целиком. В ответ возвращается аудиофайл с озвучкой. Этот способ может использоваться, например, для озвучивания книг.
<br>

Для работы с Audiogram Заказчикам предлагается gRPC контракт (proto-файлы), который можно использовать, например, для создания собственного клиентского приложения.

**Важно!** Есть 2 вида gRPC контрактов:

1. **Через полную конфигурацию запроса**: позволяет самостоятельно настраивать все параметры синтеза речи.
<br>

2. **Через пресеты**: под Заказчика заранее создается конфигурация синтеза речи (**пресет**), которая скрывает все настройки. Этот вид контракта позволяет пользователям избежать непреднамеренных ошибок конфигурации.

В следующих секциях подробнее рассмотрим эти контракты.

### Через полную конфигурацию запроса

Для создания клиентского приложения, которое будет отправлять в Audiogram запросы на синтез речи через полную конфигурацию настроек, вам понадобятся следующие .proto-файлы:

<u>Основной контракт</u>:

* [tts.proto](https://github.com/mts-ai/audiogram/blob/main/tts/full_config/v2/tts.proto) (потоковый или файловый синтез речи через полную конфигурацию настроек запроса)

<u>Зависимости</u>:

* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/tts/full_config/v2/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки. Описание этого .proto-файла представлено [в секции response_header.proto](#response_headerproto)

**Примечание 1**: Для создания собственного клиентского приложения можно использовать любой язык программирования, который есть в библиотеке для работы с gRPC. Подробную информацию об этом протоколе можно посмотреть на [https://grpc.io](https://grpc.io)

**Примечание 2**: Максимальная длина сообщения, принимаемого от клиентских приложений по gRPC (в байтах): 62914560 

#### tts.proto

##### Методы

###### StreamingSynthesize

Потоковый синтез речи.

| Имя метода | Тип запроса | Тип ответа | Описание |
|:-----------|:------------|:-----------|:---------|
| StreamingSynthesize | SynthesizeSpeechRequest | stream StreamingSynthesizeSpeechResponse |Метод потокового синтеза речи. Разбивает текст на короткие фразы, и возвращает результат по мере их синтеза.|

###### Synthesize

Синхронный файловый синтез речи.

| Имя метода | Тип запроса | Тип ответа | Описание |
|:-----------|:------------|:-----------|:---------|
| Synthesize     | SynthesizeSpeechRequest  | SynthesizeSpeechResponse |Метод синхронного файлового синтеза речи. Возвращает целый аудиофайл в формате, заданном в encoding с заголовками выбранного контейнера, пригодный для сохранения на диск.|

###### GetModelsInfo

Запрос моделей для синтеза речи.

| Имя метода | Тип запроса | Тип ответа | Описание |
|:-----------|:------------|:-----------|:---------|
| GetModelsInfo     | google.protobuf.Empty | ModelsInfo |Метод запроса списка моделей для синтеза речи. Ничего не принимает в качестве аргументов, возвращает список доступных моделей.|

##### Сообщения PROTOBUF

###### AudioEncoding

Поддерживаемые форматы аудиоданных.

| Имя | Значение| Описание |
|:----|:--------| :--------|
| ENCODING_UNSPECIFIED  | 0        | На текущий момент не поддерживается.|
| LINEAR_PCM | 1        | 1. Если данное поле выбрано при использовании метода Synthesize, то в поле SynthesizeSpeechResponse.audio вернётся WAV linear PCM аудиофайл с заголовком, содержащий целые знаковые 16-битные сэмплы в линейном распределении (PCM 16bit) и заданной частотой дискретизации в соответствии с полем sample_rate_hertz.<br> 2. При использовании метода StreamingSynthesize в поле StreamingSynthesizeSpeechResponse.audio по мере синтеза отправляются чанки linear PCM без заголовка WAV с целыми знаковыми 16-битными сэмплами в линейном распределении (PCM 16bit).              |
| FLAC   | 2        | На текущий момент не поддерживается.               |
| MULAW | 3        | 1. Если данное поле выбрано при использовании метода Synthesize, то в поле SynthesizeSpeechResponse.audio вернётся WAV PCM аудиофайл с заголовком, содержащий 8-битные сэмплы в формате mu-law и заданной частотой дискретизации в соответствии с полем sample_rate_hertz.<br> 2. При использовании метода StreamingSynthesize в поле StreamingSynthesizeSpeechResponse.audio по мере синтеза отправляются чанки PCM без заголовка WAV с 8-битными сэмплами в формате mu-law.              |
| ALAW   | 20        | 1. Если данное поле выбрано при использовании метода Synthesize, то в поле SynthesizeSpeechResponse.audio вернётся WAV PCM аудиофайл с заголовком, содержащий 8-битные сэмплы в формате a-law и заданной частотой дискретизации в соответствии с полем sample_rate_hertz.<br> 2. При использовании метода StreamingSynthesize в поле StreamingSynthesizeSpeechResponse.audio по мере синтеза отправляются чанки PCM без заголовка WAV с 8-битными сэмплами в формате a-law.               |

###### VoiceStyle

Эмоциональная окраска голоса.

| Имя | Значение | Описание |
| :-- | :-- | :-- |
| VOICE_STYLE_NEUTRAL | 0 | Спокойное состояние. |
| VOICE_STYLE_HAPPY | 1 | Радость. |
| VOICE_STYLE_ANGRY | 2 | Злость. |
| VOICE_STYLE_SAD | 3 | Грусть. |
| VOICE_STYLE_SURPRISED | 4 | Удивление. |
| VOICE_STYLE_CONVERSATIONAL | 5 | Разговорная речь. |

###### SynthesizeOptions

Опции синтеза.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| model_type  | string | Тип модели. Доступные варианты:<br /> 1) **high_quality** - относится к поколению моделей, которые отличаются улучшенными характеристиками синтеза речи. Используется для озвучки текста в потоковом и файловом режимах. |
| model_sample_rate_hertz  | uint32 | Частота дискретизации модели (в герцах). Если поле не указано, то будет подобрана наиболее близкая модель к указанной частоте дискретизации аудио.      |
| voice_style  | VoiceStyle |  Стиль речи. Значение по умолчанию - VOICE_STYLE_NEUTRAL     |
| postprocessing_mode  | PostprocessingMode | Постобработка аудио.      |
| custom_options  | map<string, CustomSynthesizeOptionValue> | Дополнительный набор опций по настройке синтеза. В custom_options выносятся экспериментальные настройки, которые еще не прошли полную проверку. На текущий момент список дополнительных настроек пустой, так как этот функционал проходит тестирование.      |

###### CustomSynthesizeOptionValue

Индивидуальные настройки синтеза.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| int32_value  | int32 | Значение типа int32.      |
| int64_value  | int64 |  Значение типа int64.     |
| number_value  | double |  Значение типа double.     |
| string_value  | string |   Значение типа string.    |
| bool_value  | bool |   Значение типа bool.    |

###### PostprocessingMode

Постобработка аудио (удаление фоновых шумов, выравнивание громкости, эквализация и другие улучшения).

| Имя | Значение| Описание |
|:----|:--------| :--------|
| POST_PROCESSING_DISABLE  | 0        | Постобработка выключена.|
| POST_PROCESSING_PHONE_CHANNEL | 1        | Этот параметр больше не поддерживается. |
| POST_PROCESSING_PRETTIFY   | 2        | Не рекомендуется использовать этот параметр. |

###### SynthesizeSpeechRequest

Настройки синтеза для файлового метода синтеза речи.

| Поле | Тип | Описание |
| :----- | :----- | :----- |
| text | string | Текст для синтеза без SSML разметки<br> (необходимо задавать только одно из полей – text или ssml).<br> Если в поле text отправить на озвучку текст с SSML-тегами, Audiogram озвучит не только текст, но и теги. |
| ssml | string | Текст для синтеза в формате SSML<br> (необходимо задавать только одно из полей – text или ssml).<br> Если в поле ssml отправить на озвучку текст без SSML-разметки, вернется ошибка синтеза. |
| language_code  | string | Язык, который используется для синтеза. В настоящее время поддерживается только русский язык.     |
| encoding             | AudioEncoding          | Формат аудио данных (кодировка).|
| sample_rate_hertz  | int32 | Частота дискретизации синтеза (в герцах).  |
| voice_name            | string       | Имя голоса. Список доступных моделей:<br> <u>женские голоса</u>:<br> <li> borisova<br> <li> kishchik<br> <u>мужские голоса</u>:<br> <li> gandzhaev<br> <li> gavrilov|
| synthesize_options            | SynthesizeOptions       | Опции синтеза аудио.|

###### StreamingSynthesizeSpeechResponse

Результат работы потокового синтеза речи.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| audio  | bytes | Байты аудиоданных без заголовка, закодированные, как указано в encoding и заданной в sample_rate_hertz частотой дискретизации.<br> Результат синтеза может прийти в нескольких ответах, по мере их синтезирования.      |
| header  | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### SynthesizeSpeechResponse

Результат работы файлового синтеза речи.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| audio  | bytes | В данном поле передаётся целый синтезированный аудиофайл с заголовками в формате, заданном в encoding и заданной в sample_rate_hertz частотой дискретизации.      |
| header  | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### ModelsInfo

Доступные голоса для синтеза речи.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| models  | repeated ModelInfo | Список доступных голосов для синтеза речи.      |
| header  | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### ModelInfo

Информация о модели синтеза речи.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| name  | string | Название модели синтеза речи.      |
| sample_rate_hertz  | uint32 | Частота дискретизации аудио данных в герцах.      |
| language_code  | string | Язык, которым озвучивается текст, отправленный на синтез. По умолчанию ru.      |
| type  | string | Тип модели. Возможные значения:<br /> <li>**high_quality** - относится к новейшему поколению моделей, которые отличаются улучшенными характеристиками синтеза речи. Используется для озвучки текста в файловом и потоковом режимах. |

### Через пресеты

Для создания клиентского приложения, которое будет отправлять в Audiogram запросы на синтез речи через пресеты (заранее созданные под Заказчика конфигурации настроек запроса), вам понадобятся следующие .proto-файлы:

<u>Основной контракт</u>:

* [tts_presets.proto](https://github.com/mts-ai/audiogram/blob/main/tts/presets/v1/tts_presets.proto) (потоковый или файловый синтез речи через заранее созданные пресеты конфигурационных настроек)

<u>Зависимости</u>:

* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/tts/presets/v1/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки. Описание этого .proto-файла представлено [в секции response_header.proto](#response_headerproto)

**Примечание 1**: Для создания собственного клиентского приложения можно использовать любой язык программирования, который есть в библиотеке для работы с gRPC. Подробную информацию об этом протоколе можно посмотреть на [https://grpc.io](https://grpc.io)

**Примечание 2**: Максимальная длина сообщения, принимаемого от клиентских приложений по gRPC (в байтах): 62914560 

#### tts_presets.proto

##### Методы

###### StreamingSynthesize

Потоковый синтез речи.

| Имя метода | Тип запроса | Тип ответа | Описание |
|:-----------|:------------|:-----------|:---------|
| StreamingSynthesize | SynthesizeSpeechRequest | stream StreamingSynthesizeSpeechResponse |Метод потокового синтеза речи. Разбивает текст на короткие фразы, и возвращает результат по мере их синтеза.|

###### Synthesize

Синхронный файловый синтез речи.

| Имя метода | Тип запроса | Тип ответа | Описание |
|:-----------|:------------|:-----------|:---------|
| Synthesize     | SynthesizeSpeechRequest  | SynthesizeSpeechResponse |Метод синхронного файлового синтеза речи. Возвращает целый аудиофайл в формате, заданном в encoding с заголовками выбранного контейнера, пригодный для сохранения на диск.|

##### Сообщения PROTOBUF

###### Preset

Эта структура содержит информацию о пресете настроек, который необходимо использовать для синтеза речи.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| preset_name | string | Название пресета. |
| preset_version | string | Версия пресета. |

Название и версию пресета, который вам надо использовать, можно получить у менеджеров Audiogram.

###### SynthesizeSpeechRequest

Настройки синтеза для синтеза речи.

| Поле | Тип | Описание |
| :----- | :----- | :----- |
| text | string | Текст для синтеза без SSML разметки<br> (необходимо задавать только одно из полей – text или ssml).<br> Если в поле text отправить на озвучку текст с SSML-тегами, Audiogram озвучит не только текст, но и теги. |
| ssml | string | Текст для синтеза в формате SSML<br> (необходимо задавать только одно из полей – text или ssml).<br> Если в поле ssml отправить на озвучку текст без SSML-разметки, вернется ошибка синтеза. |
| preset | Preset | Сообщение типа Preset (описано выше). |

###### StreamingSynthesizeSpeechResponse

Результат работы потокового синтеза речи.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| audio  | bytes | Байты аудиоданных без заголовка, закодированные, как указано в encoding и заданной в sample_rate_hertz частотой дискретизации.<br> Результат синтеза может прийти в нескольких ответах, по мере их синтезирования.      |
| header  | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

###### SynthesizeSpeechResponse

Результат работы файлового синтеза речи.

| Поле              | Тип                        | Описание                       |
| :------------     |:---------                  | :------------------------------|
| audio  | bytes | В данном поле передаётся целый синтезированный аудиофайл с заголовками в формате, заданном в encoding и заданной в sample_rate_hertz частотой дискретизации.      |
| header  | mts.ai.audiogram.response_header.v1.ResponseHeader | Сообщение типа ResponseHeader. |

### Использование SSML-разметки

SSML (Speech Synthesis Markup Language) – это язык разметки с фиксированным набором тегов и атрибутов, основанный на XML (но без тега xml в начале) и применяемый для синтеза речи. Его можно использовать, чтобы настроить скорость и звучание голоса.

Настройка проводится с помощью SSML-тегов, которые нужно указать в тексте, отправляемом на синтез.

**Примечание:** текст без тегов необходимо писать в поле SynthesizeSpeechRequest.text

На данный момент в **Audiogram** поддерживаются следующие SSML-теги:

| Тег | Описание | Параметры тега |
| :-- | :-- | :-- |
| **speak** | Обязательный тег для работы с SSML. В него должен быть обернут весь текст, отправляемый на синтез.<br> При помощи дополнительных параметров может управлять скоростью и высотой тона (питчем) всего текста.<br> Должен сопровождаться закрывающим тегом `<speak> ... </speak>`. | <li> **speed** (скорость речи) – положительное число, рекомендуемый интервал [от 0.1 до 2.0]<br> (значения меньше единицы – медленнее, больше – быстрее).<br> Данный параметр является опциональным. Если параметр не указан, его значение по умолчанию = 1.0<br> <p>&nbsp;</p> <li> **pitch** (высота тона) – рекомендуемый интервал [от -1.0 до 1.0], но допустимы и значения вне данного диапазона. К примеру, при значении 5 получится металлический голос.<br> Отрицательные значения – низкий тон, положительные – высокий.<br> Данный параметр является опциональным. Если параметр не указан, его значение по умолчанию = 0.0 |
| **prosody** | Этот тег позволяет управлять скоростью и высотой тона произвольного количества предложений и слов. Например, его можно использовать, чтобы изменить скорость и высоту тона прямой речи, тем самым выделяя ее на фоне речи рассказчика. <br> <p>&nbsp;</p> Тег **prosody** имеет те же параметры, что и **speak**, и должен сопровождаться закрывающим тегом `<prosody> ... </prosody>`. <br> Конструкцию `<prosody> ... </prosody>` можно использовать внутри конструкции `<speak> ... </speak>`. | <li> **speed** (скорость речи) – положительное число, рекомендуемый интервал [от 0.1 до 2.0]<br> (значения меньше единицы – медленнее, больше – быстрее).<br> Данный параметр является опциональным. Если параметр не указан, его значение по умолчанию = 1.0<br> <p>&nbsp;</p> <li> **pitch** (высота тона) – рекомендуемый интервал [от -1.0 до 1.0], но допустимы и значения вне данного диапазона. К примеру, при значении 5 получится металлический голос.<br> Отрицательные значения – низкий тон, положительные – высокий.<br> Данный параметр является опциональным. Если параметр не указан, его значение по умолчанию = 0.0 |
| **break** | Добавляет паузу произвольной длины в секундах в любое место. Этот тег является самозакрывающимся - `<break />`. | <li> **time** (время продолжительности паузы в секундах) - данный параметр является опциональным. Если его не указывать, длительность паузы по умолчанию - 1 секунда.<br> <p>&nbsp;</p> Если вы указываете время паузы, необходимо обязательно вставить единицу измерения **s** (секунды) после количества секунд - `<break time="2s"/>` |
| **voice** | Указывает каким голосом и эмоцией необходимо озвучить текст. Доступен для синтеза только с помощью модели **high_quality**. | <li> **name** - имя спикера: <br> <p>&nbsp;</p> <u>Мужские голоса</u>: <br> - gandzhaev <br> - gavrilov <br> <p>&nbsp;</p> <u>Женские голоса</u>: <br> - borisova <br> - kishchik <p>&nbsp;</p> <li> **style** - эмоциональная окраска голоса: <br> - neutral (спокойное состояние) <br> - sad (грусть) <br> - happy (радость) <br> - angry (злость) <br> - surprised (удивление) |
| **say-as** | Позволяет настроить озвучку разных категорий числительных. Более подробно этот тег описан в следующих секциях. | <li> **interpret-as** - обязательный атрибут, в котором указывается категория числительного.<br><br>  <li> **format** - необязательный атрибут, в котором указывается в каком роде, числе и падеже необходимо провести озвучку.<br><br>  <li> **detail** - необязательный атрибут, который можно указать для некоторых категорий числительных. В нем передаются дополнительные детали. |
| **phoneme** | Позволяет озвучивать слова с помощью фонем. Более подробно этот тег описан в следующих секциях. | <li> **alphabet** - обязательный атрибут, в котором указывается какую фонемную нотацию следует использовать.<br><br>  <li> **ph** - обязательный атрибут, в котором указывается транскрипция озвучиваемого слова. |

Параметры тегов указываются внутри треугольных скобок в виде

<название_тега название_параметра1="величина_параметра1" название_параметра2="величина_параметра2" закрытие тега>

**Важно!** Обратите внимание на кавычки, в которых указываются величины параметров. Необходимо использовать " (ASCII code 34).

**Как поставить ударение в слове**

Некоторые слова могут читаться по-разному. Например, «жАркое» или «жаркОе». При помощи SSML-разметки можно указать где надо делать ударение. Для этого после ударной гласной необходимо вставить {'} :
* «жа{'}ркое», чтобы получилось «жАркое»; и
* «жарко{'}е», чтобы получилось «жаркОе».

**Важно!** В фигурных скобках необходимо использовать одинарную кавычку ' (ASCII code 39).

**Дополнительно**

1. Если отправить какой-то текст без разметки на озвучку в поле text, а потом этот же текст обернуть только в тег <speak></speak> и отправить на озвучку в поле ssml, то текст будет озвучен одинаково.

2. Если текст с SSML-тегами отправить на озвучку в поле text, то Audiogram озвучит не только текст, но и теги. Например, если отправить "<speak>Привет мир</speak>", то озвучка будет - "спик привет мир спик".

3. Знак ударения {'} синтез не считает ssml-тегом и он будет обработан как ударение и в text, и в ssml.

4. Синтез текста без SSML-разметки и синтез этого же текста с разметкой не будут различаться по нагрузке на систему.

#### Тег say-as для озвучки числительных

Русский язык относится к группе флективных языков. Это означает, что различные грамматические категории (род, число, падеж и т. д.) выражаются в пределах одного слова при помощи окончаний, суффиксов и других морфологических средств.

Такие нюансы делают русский язык не самым простым для озвучки машиной. ML-модели могут допускать ошибки, особенно при озвучке различных числительных. Избежать ошибок позволяет настройка параметров озвучки при помощи SSML-тега say-as.

В этом разделе рассмотрим как настроить озвучку числительных при помощи тега say-as, но сначала вспомним какие у числительных бывают род, число и падеж, разделим числительные на категории, а также рассмотрим структуру тега say-as.

**<u>Род</u>**

| Род | Описание | Пример |
| :-- | :-- | :-- |
| masculine | мужской род | один файл |
| feminine | женский род | одна папка |
| neuter | средний род | одно окружение |

**<u>Число</u>**

Числительные бывают единственного и множественного числа. По умолчанию числительные озвучиваются в единственном числе.

Если необходимо озвучить во множественном числе, это надо указать с помощью значения **plural**. Примеры представлены в дальнейших описаниях.

| Число | Описание | Пример |
| :-- | :-- | :-- |
| plural | множественное число | три файла |

**<u>Падеж</u>**

| Падеж | Описание | Пример |
| :-- | :-- | :-- |
| nominative | именительный - отвечает на вопросы кто?/что? | кто?/что? - один рубль |
| genitive | родительный - отвечает на вопросы кого?/чего? | нет кого?/чего? - пяти рублей |
| dative | дательный - отвечает на вопросы кому?/чему? | дать кому?/чему? - четырем администраторам |
| accusative | винительный - отвечает на вопросы кого?/что? | вижу кого?/что? - три файла |
| ablative | творительный - отвечает на вопросы кем?/чем? | установлено кем?/чем? - двумя администраторами |
| prepositional | предложный - отвечает на вопросы о ком?/о чем? | рассказываю о ком?/о чем? - о десяти рублях |

**<u>Категории числительных</u>**

| Категория числительных | Описание | Пример |
| :-- | :-- | :-- |
| cardinal | количественные числительные | один файл |
| ordinal | порядковые числительные | первый файл |
| date | дата | одиннадцатого августа две тысячи двадцать четвертого |
| time | время | одиннадцать часов двадцать четыре минуты |
| telephone | номер телефона | семь, девятьсот пятнадцать, сто девяносто, ноль семь, ноль два |
| money | денежная сумма | десять рублей пятьдесят копеек |
| split-by | произнесение числа по группам его цифр | сто двадцать три четыреста пятьдесят шесть |
| fraction | дробные числа | две третьих |
| decimal | десятичные дроби | одна целая одна десятая |
| non-roman | правильное произнесение букв, которые можно спутать с римскими цифрами | размер одежды икс эль |

**<u>Структура тега say-as</u>**

У тега say-as есть ряд обязательных и необязательных атрибутов:

| Элемент | Описание | Обязательность | Пример |
| :-- | :-- | :-- | :-- |
| say-as | Тег. | Обязательный | `<speak><say-as interpret-as="cardinal" format="feminine_nominative">1</say-as> ложка</speak>` |
| interpret-as | Атрибут, указывающий категорию числительного. | Обязательный | `<speak><say-as interpret-as="cardinal" format="feminine_nominative">1</say-as> ложка</speak>` |
| format | Атрибут, указывающий в каком числе, роде и падеже надо озвучить числительное.<br><br> Если числительное в единственном числе, нужно указать род и падеж.<br><br> Если числительное во множественном числе, нужно указать plural и падеж. | Необязательный | `<speak><say-as interpret-as="cardinal" format="feminine_nominative">1</say-as> ложка</speak>` |
| detail | Дополнительный атрибут, его описание представлено в категориях числительных, в которых он присутствует.  | Необязательный | `<speak><say-as interpret-as="cardinal" format="nominative" detail = "3">1</say-as> 12345 </speak>` |

Рассмотрим структуру тега say-as на конкретном примере. Представим, что нам нужно озвучить фразу "1 ложка". В этом примере 1 - это количественное (cardinal) числительное в единственном числе. Так как слово "ложка" женского рода и в именительном падеже, нужно, чтобы цифра 1 была озвучена как "одна". Действуем следующим образом:

1. Сначала обрамляем фразу в тег speak:
`<speak>1 ложка</speak>`
<br>

2. Теперь добавляем тег say-as и его обязательный атрибут interpret-as. Это нужно сделать вокруг числительного. Слово "ложка" должно быть за их пределами:
`<speak><say-as interpret-as="cardinal">1</say-as> ложка</speak>`
<br>

3. По умолчанию, если не указать атрибут format, числительное озвучивается в мужском роде, единственном числе и именительном падеже. То есть, если мы оставим как было сделано на шаге 2, фраза будет озвучена как "один ложка". Это неправильно, поэтому добавляем атрибут format, в котором указываем женский род и именительный падеж:
`<speak><say-as interpret-as="cardinal" format="feminine_nominative">1</say-as> ложка</speak>`
<br>

Теперь фраза будет озвучена правильно - "одна ложка".
<br>

А теперь рассмотрим пример со множественным числом. Представим, что нам нужно озвучить фразу "нет 5 ложек". В этом примере 5 - количественное (cardinal) числительное. Существительное представлено во множественном числе и родительном (genitive) падеже. Числительное надо озвучить также. Действуем следующим образом:

1. Сначала обрамляем фразу в тег speak:
`<speak>нет 5 ложек</speak>`
<br>

2. Теперь добавляем тег say-as и его обязательный атрибут interpret-as. Это нужно сделать вокруг числительного. Слова "нет" и "ложек" должны быть за их пределами:
`<speak>нет <say-as interpret-as="cardinal">5</say-as> ложек</speak>`
<br>

3. По умолчанию, если не указать атрибут format, числительное озвучивается в мужском роде, единственном числе и именительном падеже. То есть, если мы оставим как было сделано на шаге 2, фраза будет озвучена как "нет пять ложек". Это неправильно, поэтому добавляем атрибут format, в котором указываем множественное число и родительный падеж:
`<speak>нет <say-as interpret-as="cardinal" format="plural_genitive">5</say-as> ложек</speak>`
<br>

Теперь фраза будет озвучена правильно - "нет пяти ложек".
<br>

##### cardinal

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Произнесение количественного числительного в указанном роде, числе и падеже. | `<speak><say-as interpret-as="cardinal" format="feminine_nominative">1</say-as> ложка</speak>` | Количественное числительное произносится в masculine nominative (в единственном числе). |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="cardinal" format="accusative">1</say-as></speak>` | `<speak>одного</speak>` | Не указан род в format, раскрываем в masculine accusative. |
| `<speak><say-as interpret-as="cardinal" format="dative_plural">1</say-as></speak>` | `<speak>одним</speak>` | Изменение порядка аргументов внутри format ошибкой не считается. Указаны число (вместо рода) и падеж. Числительное будет озвучено в plural dative. |
| `<speak><say-as interpret-as="cardinal" format="feminine">1</say-as></speak>` | `<speak>одна</speak>` | Не указан падеж в format, раскрываем в feminine nominative. |
| `<speak><say-as interpret-as="cardinal" format="masculine_plural_dative">1</say-as></speak>` | `Error, <speak>один</speak>` | Неконсистентный тег (в format указаны и род, и множественное число) - числительное будет озвучено по умолчанию, но параллельно в лог будет сделана запись об ошибке. |
| `<speak><say-as interpret-as="cardinal" format="plural_dative">1</say-as></speak>` | `<speak>одним</speak>` | Указаны множественное число (вместо рода) и падеж, хотя числительное - 1. Будет озвучено в plural dative. |
| `<speak><say-as interpret-as="cardinal" format="plural_dative">1</say-as></speak> ложку` | `Error` | Произойдет ошибка синтеза, потому что слово "ложку" находится за пределами тега speak. |
| `<speak><say-as interpret-as="cardinal" format="plural_dative">1 ложку</say-as></speak>` | `Error, <speak>одним</speak>` | Неконсистентный тег (слово "ложку" находится внутри тега say-as) - из тега уберется все, кроме числительного, после чего оно будет озвучено по значению format. Также параллельно в лог будет сделана запись об ошибке. |
| `<speak><say-as interpret-as="cardinal">1</say-as></speak>` | `<speak>один</speak>` | Тут не указан format, значит раскрываем по умолчанию в masculine nominative. |
| `<speak><say-as interpret-as="cardinal">-1</say-as></speak>` | `<speak>минус один</speak>` | Если перед числом стоит минус, он будет озвучен. |
| `<speak>нет <say-as interpret-as="cardinal" format="accusative">1</say-as> ботинка</speak>` | `<speak>нет одного ботинка</speak>` | Число внутри тега следует писать без пробелов. Так как в format не указан род, то числительное будет озвучено в masculine accusative. <br><br>Если необходимо добавить контекст (правый, левый, правый и левый), то его следует писать, сохраняя пробелы как в обычном тексте. |
| `<speak>нет <say-as interpret-as="cardinal" format="genitive">1</say-as> ботинков</speak>` | `<speak>нет одного ботинков</speak>` | Теги не подразумевают склонение контекста. Так как в format не указано множественное число, то числительное будет озвучено в masculine genitive. |

##### ordinal

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Произнесение порядкового числительного в указанном роде, числе и падеже. | `<speak><say-as interpret-as="ordinal" format="feminine_nominative">1</say-as> этаж</speak>` | Порядковое числительное произносится в masculine nominative (в единственном числе). |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="cardinal">1</say-as></speak>` | `<speak>первый</speak>` | Тут не указан format, значит раскрываем по умолчанию в masculine nominative. |
| `<speak><say-as interpret-as="cardinal">-1</say-as></speak>` | `<speak>минус первый</speak>` | Если перед числом стоит минус, он будет озвучен. |
| `<speak><say-as interpret-as="cardinal" format="feminine">1</say-as></speak>` | `<speak>первая</speak>` | Не указан падеж в format, раскрываем в feminine nominative. |
| `<speak><say-as interpret-as="cardinal" format="accusative">1</say-as></speak>` | `<speak>первого</speak>` | Не указан род в format, раскрываем в masculine accusative. |
| `<speak><say-as interpret-as="cardinal" format="plural_dative">1</say-as></speak>` | `<speak>первым</speak>` | Указаны число (вместо рода) и падеж, раскрываем в plural dative. |
| `<speak>нет <say-as interpret-as="cardinal" format="accusative">1</say-as> этажа</speak>` | `<speak>нет первого этажа</speak>` | Число внутри тега следует писать без пробелов. <br><br>Если необходимо добавить контекст, то его следует писать, сохраняя пробелы как в обычном тексте. |
| `<speak><say-as interpret-as="cardinal" format="dative_plural">1</say-as></speak>` | `<speak>первым</speak>` | Изменение порядка аргументов внутри format не считается ошибкой. Указаны число (вместо рода) и падеж, поэтому числительное будет озвучено в plural dative. |
| `<speak><say-as interpret-as="cardinal" format="masculine_plural_dative">1</say-as></speak>` | `Error, <speak>первый</speak>` | Неконсистентный тег (в format указаны и род и множественное число) - числительное будет озвучено по умолчанию. Параллельно в лог будет сделана запись об ошибке. |
| `<speak><say-as interpret-as="cardinal" format="plural_dative">1 этажам</say-as></speak>` | `Error, <speak>первым</speak>` | Неконсистентный тег (слово "этажам" находится внутри тега say-as) - из тега уберется все, кроме числительного, после чего оно будет озвучено по значению format. Также параллельно в лог будет сделана запись об ошибке. |
| `<speak><say-as interpret-as="cardinal" format="plural_dative">1</say-as></speak> этажам` | `Error` | Произойдет ошибка синтеза - слово "этажам" находится за пределами тега speak. |
| `<speak>нет <say-as interpret-as="cardinal" format="genitive">1</say-as> этажей</speak>` | `<speak>нет первого этажей</speak>` | Теги не подразумевают склонение контекста. Так как в format не указано множественное число, то числительное будет озвучено в masculine genitive. |

##### date

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Произнесение дат в указанном формате. | `<speak><say-as interpret-as="date" format="nominative" detail="d.m.y">11.08.2024</say-as></speak>` | d.m.y в именительном падеже. |

| detail | Описание |
| :-- | :-- |
| d.m.y (d-m-y, d/m/y) | Любые комбинации дня, месяца и года, разделенные одним из 3 символов "." или "-" или "/" |
| _fulldate | Полная озвучка даты. |
| _word | Добавление слова "год"/"года" к дате. |
| _fulldate и _word (можно использовать вместе) | Полная озвучка даты и добавление слова "год"/"года" к дате. |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="date">11.08.2024</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый</speak>` | Надо озвучить день, месяц и год. <br><br>detail не указан, по умолчанию d.m.y <br><br>format не указан, по умолчанию дата будет озвучена в именительном падеже |
| `<speak><say-as interpret-as="date" detail="d.m.y">11.08.2024</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый</speak>` | В detail день, месяц и год указаны с разделителем. <br><br>format не указан, по умолчанию дата будет озвучена в именительном падеже |
| `<speak><say-as interpret-as="date" format="genitive" detail="d.m.y">11.08.2024</say-as></speak>` | `<speak>одиннадцатого августа две тысячи двадцать четвертого</speak>` | В detail день, месяц и год указаны с разделителем. <br><br>format указан - дата будет озвучена в родительном падеже. |
| `<speak><say-as interpret-as="date" detail="d.m">11.08</say-as></speak>` | `<speak>одиннадцатое августа</speak>` | В detail день и месяц указаны с разделителем. <br><br>format не указан - по умолчанию дата будет озвучена в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="y">2024</say-as></speak>` | `<speak>две тысячи двадцать четвертый</speak>` | В detail только год, разделитель не нужен и не указывается. <br><br>format не указан - по умолчанию озвучка будет выполнена в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="m.y">08.2024</say-as></speak>` | `<speak>август две тысячи двадцать четвертый</speak>` | В detail месяц и год указаны с разделителем. <br><br>format не указан - по умолчанию дата будет озвучена в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="m">08</say-as></speak>` | `<speak>август</speak>` | в detail только месяц , разделитель не нужен и не указывается. <br><br>format не указан, по умолчанию в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="d">11</say-as></speak>` | `<speak>одиннадцатое</speak>` | в detail только день, разделитель не нужен и не указывается. <br><br>format не указан, по умолчанию озвучка будет выполнена в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="d-m-y">11-08-2024</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый</speak>` | Используется разделитель (-) <br><br>format не указан - по умолчанию озвучка будет выполнена в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="d/m/y">11/08/2024</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый</speak>` | Используется разделитель (/) <br><br>format не указан - по умолчанию озвучка будет выполнена в именительном падеже. |
| `<speak><say-as interpret-as="date" detail="m/d/y">08/11/2024</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый</speak>` | "американский" формат дат.<br><br> format не указан - по умолчанию озвучка будет выполнена в именительном падеже. |
| `<speak><say-as interpret-as="ordinal" detail="y">2024</say-as></speak>` | `Error, <speak>две тысячи двадцать четыре</speak>` | Неконсистентный тег - число будет озвучено по умолчанию как cardinal masculine nominative |
| `<speak><say-as interpret-as="date" detail="m.y_fulldate">08.24</say-as></speak>` | `<speak>август две тысячи двадцать четыре </speak> ` |  |
| `<speak><say-as interpret-as="date" detail="d.m.y_word">11.08.2024</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый год</speak>` | Для корректной озвучки необходимо добавить format и указать правильный падеж. |
| `<speak><say-as interpret-as="date" detail="d.m.y_word_fulldate">11.08.24</say-as></speak>` | `<speak>одиннадцатое августа две тысячи двадцать четвертый год</speak>` | Для корректной озвучки необходимо добавить format и указать правильный падеж. |

##### time

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Произнесение времени в указанном формате. | `<speak><say-as interpret-as="time" format="nominative" detail="h:m">11:24</say-as></speak>` | Часы и минуты через : в именительном падеже (h:m). |

| detail | Описание |
| :-- | :-- |
| h:m | Указание формата (hm: часы и минуты или hms: часы, минуты, секунды) и разделителя (: . -) |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="time" detail="h:m">11:24</say-as></speak>` | `<speak>одиннадцать часов двадцать четыре минуты</speak>` | В detail указаны часы и минуты.<br><br> format не указан - по умолчанию время будет озвучено в именительном падеже. |
| `<speak><say-as interpret-as="time" detail="h:m:s">11:24:03</say-as></speak>` | `<speak>одиннадцать часов двадцать четыре минуты три секунды</speak>` | В detail указаны часы, минуты и секунды.<br><br> format не указан - по умолчанию время будет озвучено в именительном падеже. |
| `<speak><say-as interpret-as="time" format="genitive" detail="h:m">11:24</say-as></speak>` | `<speak>одиннадцати часов двадцати четырёх минут</speak>` | Указаны detail и format. Время будет озвучено в родительном падеже. |
| `<speak><say-as interpret-as="time">11:24</say-as></speak>` | `<speak>одиннадцать часов двадцать четыре минуты</speak>` | Не указан ни format, ни detail.<br><br> По умолчанию время будет озвучено в именительном падеже в формате h:m |

##### telephone

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Озвучка российских телефонных номеров (русский формат и полные номера 10-11 цифр; номер начинается с +7, 8 или кода оператора) | `<speak><say-as interpret-as="telephone" detail="RU">+7 (909) 2282424</say-as></speak>` | По умолчанию обрабатываются номера телефонов 9-11 цифр (RU).<br><br> Без + (либо выносить его за say-as) |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="telephone">7 (915) 1900702</say-as></speak>` | `<speak>семь, девятьсот пятнадцать, сто девяносто ноль семь ноль два</speak>` |  |
| `<speak><say-as interpret-as="telephone" detail="RU">7 (915) 1900702</say-as></speak>` | `<speak>семь девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` |  |
| `<speak><say-as interpret-as="telephone">79151900702</say-as></speak>` | `<speak>семь девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` |  |
| `<speak><say-as interpret-as="telephone">7-915-190-07-02</say-as></speak>` | `<speak>семь девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` |  |
| `<speak><say-as interpret-as="telephone">8 (915) 1900702</say-as></speak>` | `<speak>восемь девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` |  |
| `<speak><say-as interpret-as="telephone">9151900702</say-as></speak>` | `<speak>девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` |  |
| `<speak><say-as interpret-as="telephone">7021</say-as></speak><speak>девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` | `<speak>семь тысяч двадцать один</speak>` | Категория telephone не работает с короткими номерами. Если нужно озвучить как "семьдесят двадцать один" - используйте категорию split-by. |
| `<speak><say-as interpret-as="telephone">+7 (915) 1900702</say-as></speak>` | `Warning, <speak> семь девятьсот пятнадцать сто девяносто ноль семь ноль два</speak>` | Важно выносить + за тэг say-as. Правильно: `<speak>+<say-as interpret-as="telephone">7 (915) 1900702</say-as></speak>` |

##### money

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Произнесение денежной суммы (с возможностью добавления валюты). | `<speak><say-as interpret-as="money" format="genitive" detail="RUB">10.65</say-as></speak>` | RUB (рубли) |

| detail | Описание |
| :-- | :-- |
| RUB | Российские рубли и копейки |
| USD | Американские доллары и центы |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="money" format="nominative"detail="RUB">10.65</say-as></speak>` | `<speak>десять рублей шестьдесят пять копеек</speak>` |  |
| `<speak><say-as interpret-as="money" format="nominative"detail="RUB">-10.65</say-as></speak>` | `<speak>минус десять рублей шестьдесят пять копеек</speak>` | Если перед числом стоит минус, он будет озвучен. |
| `<speak><say-as interpret-as="money" format="nominative"detail="RUB">10</say-as></speak>` | `<speak>десять рублей</speak>` | Если передается число без точки, то оно будет озвучено как "столько-то рублей". |
| `<speak><say-as interpret-as="money" format="nominative"detail="RUB">0.65</say-as></speak>` | `<speak>шестьдесят пять копеек</speak>` |  |
| `<speak><say-as interpret-as="money" format="nominative"detail="RUB">10.00</say-as></speak>` | `<speak>десять рублей</speak>` |  |
| `<speak>нет <say-as interpret-as="money">10.65</say-as></speak>` | `<speak>нет десять рублей шестьдесят пять копеек</speak>` | Теги не подразумевают склонения в зависимости от контекста. По умолчанию число будет озвучено в именительном падеже. Чтобы его корректно озвучить в родительном падеже, необходимо добавить атрибут format и указать в нем родительный падеж (genitive). |
| `<speak><say-as interpret-as="money" format="nominative"detail="USD">10.65</say-as></speak>` | `<speak>десять долларов шестьдесят пять центов</speak>` |  |
| `<speak><say-as interpret-as="money">10.65</say-as></speak>` | `<speak>десять рублей шестьдесят пять копеек</speak>` |  |

##### split-by

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Озвучка чисел группами. | `<speak><say-as interpret-as="split-by" detail="3">123456</say-as></speak>` | По умолчанию число озвучивается группами по 1 цифре. |

| detail | Описание |
| :-- | :-- |
| 1, 2 или 3 | Указывает как озвучить большое число - по 1, 2 или 3 цифры. Принимает значение от 1 до 3. |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="split-by" detail="3">123456</say-as></speak>` | `<speak>сто двадцать три четыреста пятьдесят шесть</speak>` |  |
| `<speak><say-as interpret-as="split-by" detail="2">123456</say-as></speak>` | `<speak>двенадцать тридцать четыре пятьдесят шесть</speak>` |  |
| `<speak><say-as interpret-as="split-by" detail="1">123456</say-as></speak>` | `<speak>один два три четыре пять шесть</speak>` |  |
| `<speak><say-as interpret-as="split-by" detail="3">12345</say-as></speak>` | `<speak>сто двадцать три сорок пять</speak>` | Если число не кратно шагу, то оставшаяся последовательность читается отдельно. |

##### fraction

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Озвучка дробей.  | `<speak><say-as interpret-as="fraction" format="nominative">2/3</say-as></speak>` | По умолчанию озвучка осуществляется в именительном падеже без специфичных слов вроде "половина/четверть/треть".  |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="fraction">2/3</say-as></speak>` | `<speak>две третьих</speak>` |  |
| `<speak><say-as interpret-as="fraction">-2/3</say-as></speak>` | `<speak>минус две третьих</speak>` |  |
| `<speak><say-as interpret-as="fraction">1/2</say-as></speak>` | `<speak>одна вторая</speak>` |  |
| `<speak><say-as interpret-as="fraction">2/3</say-as> чашками</speak>` | `<speak>две третьих чашками</speak>` | Тэги не подразумевают склонения контекста. Озвучка выполняется в соответствии со значениями атрибутов. Если format не указан, то по умолчанию озвучка выполняется в именительном падеже. |

##### decimal

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Озвучка десятичных дробей.<br><br> "2/3" не будет обрабатываться в рамках decimal (обработается в рамках fraction). "0.25 стакана" не будет озвучено как "четверть стакана". | `<speak><say-as interpret-as="decimal" format="nominative">1.1</say-as></speak>` | По умолчанию озвучка осуществляется в именительном падеже без специфичных слов вроде "половина/четверть/треть". |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak><say-as interpret-as="decimal">1.1</say-as></speak>` | `<speak>одна целая одна десятая</speak>` |  |
| `<speak><say-as interpret-as="decimal">-1.1</say-as></speak>` | `<speak>минус одна целая одна десятая</speak>` |  |
| `<speak><say-as interpret-as="decimal">1.10</say-as></speak>` | `<speak>одна целая десять сотых</speak>` | Округления не будет. Если оно нужно, необходимо подать на вход "1.1" вместо "1.10". |
| `<speak><say-as interpret-as="decimal" format="genitive">1.1</say-as></speak>` | `<speak>одной целой одной десятой</speak>` |  |
| `<speak>нет <say-as interpret-as="decimal" format="genitive">1.1</say-as> миллионах</speak>` | `<speak>нет одной целой одной десятой миллионах</speak>` | Контекст не склоняется. |

##### non-roman

| Описание | Вид | Значение по умолчанию |
| :-- | :-- | :-- |
| Озвучка элементов, которые можно принять за римские цифры.<br><br> Например, "витамин C, размер M, тариф X". | `<speak>Раззмер <say-as interpret-as="non-roman">M</say-as></speak>` |  |

Примеры использования:

| Оформление | Как будет озвучено | Комментарий |
| :-- | :-- | :-- |
| `<speak>Размер<say-as interpret-as="non-roman"> M</say-as></speak> ` | `<speak>Размер эм</speak>` | Любые слова, не относящиеся к non-roman числовым значениям должны находится ВНЕ тега say-as. |
| `<speak>Размер<say-as interpret-as="non-roman"> XL</say-as></speak> ` | `<speak>Размер икс эль</speak>` | Non-roman значения будут представлены в буквенном виде. |

#### Тег phoneme для озвучки с помощью фонем

В русском языке, как и в других языках, существуют различные фонетические процессы, из-за которых некоторые слова могут писаться и произноситься по-разному. К таким процессам относятся:

* Оглушение - пишем "книжка", но произносим "кни[ш]ка".
* Озвончение - пишем "отбор", но произносим "о[д]бор".
* Смягчение - пишем "лесть", но в речи смягчаем букву "с" - "ле[с']ть".
* и другие...

Если Вас не устраивает как Audiogram озвучивает какое-то слово, можно использовать SSML-тег phoneme для правильной озвучки при помощи фонем. **Примечание**: эта функциональность поддерживается только для русского языка.

В этом разделе вкратце разберем что такое фонема и как использовать тег phoneme.

##### Буквы, звуки и фонемы

В русском языке буквы делятся на гласные и согласные. Каждая буква дает какой-то звук.

Но, если обратить внимание, слышно, что одна и та же буква может давать разные звуки. Например, буква "Я" в слове "клятва" звучит как "а", а в слове "пяти" (не хватает пяти рублей) буква "Я" звучит как "и". А в слове "входят" буква "Я" звучит вроде бы как в "клятве", но все равно не так, как будто не так ярко.

Получается, что буквы обозначают некие множества звуков. Эти множества звуков называются фонемами.

##### Структура тега phoneme

У тега say-as есть ряд обязательных и необязательных атрибутов:

| Элемент | Описание | Обязательность | Пример |
| :-- | :-- | :-- | :-- |
| phoneme | Тег.<br> **Важно!** В рамках 1 тега должно быть только 1 слово. | Обязательный | `<speak> <phoneme alphabet="avan" ph="п р' и в' е+ т"> привет</phoneme>! У тебя три непрочитанных сообщения </speak>` |
| alphabet="" | Атрибут, указывающий какую фонемную нотацию следует использовать.<br> **Важно!** Audiogram поддерживает нотацию Аванесова (необходимо указать alphabet = "**avan**") | Обязательный | `<speak> <phoneme alphabet="avan" ph="п р' и в' е+ т"> привет</phoneme>! У тебя три непрочитанных сообщения </speak>` |
| ph="" | Атрибут, содержащий транскрипцию слова, которое необходимо озвучить. | Обязательный | `<speak> <phoneme alphabet="avan" ph="п р' и в' е+ т"> привет</phoneme>! У тебя три непрочитанных сообщения </speak>` |

Рассмотрим структуру тега phoneme на конкретном примере. Сразу стоит отметить, что работать с тегом phoneme рекомендуется сотруднику, обладающему знаниями о фонетических процессах в русском языке. Это важно, чтобы прописать корректную транскрипцию озвучиваемого слова в атрибуте ph.

Представим, что нам нужно озвучить фразу "Привет, дед!". Допустим, нам не нравится, что в озвучке по умолчанию вторая буква "д" в слове "дед" звучит звонко - "деД" - и мы хотим с помощью тега phoneme ее оглушить, чтобы она звучала естественно - "деТ".

Действуем следующим образом:

1. Сначала обрамляем фразу в тег speak:
`<speak>Привет, дед!</speak>`
<br>

2. Теперь добавляем тег phoneme вокруг слова "дед". Помним, что в 1 теге должно быть 1 слово:
`<speak>Привет, <phoneme>дед</phoneme>!</speak>`
<br>

3. Добавляем обязательный атрибут alphabet. В нем прописываем **avan**, так как поддерживается нотация Аванесова:
`<speak>Привет, <phoneme alphabet="avan">дед</phoneme>!</speak>`
<br>

4. Добавляем обязательный атрибут ph (список поддерживаемых фонем по концепции Аванесова представлен в следующем разделе).

    Первая буква "д" смягчается последующей гласной, поэтому она даст мягкий звук [д'].
    Буква "е" под ударением - она даст звук [е+].
    Вторая буква "д" в речи оглушается, поэтому она даст не твердый звук [д], а твердый звук [т].
    В итоге получается:
    `<speak>Привет, <phoneme alphabet="avan" ph="д' е+ т">дед</phoneme>!</speak>`
    Теперь слово "дед" будет произнесено корректно - с глухим звуком "т" на конце - "деТ".

##### Список поддерживаемых фонем

| Буква | Фонема (концепция Аванесова) | Пример слова и его транскрипции |
| :-- | :-- | :-- |
| А, а (в ударном слоге) | а+ | дв**а** [д в а+] |
| А, а (в предударном слоге) | а | р**а**ботал [р а б о+ т ъ л] |
| А, а (в остальных случаях) | ъ | оплачив**а**ли [а п л а+ ч и в ъ л' и] |
| Б, б (твердая) | б | **б**олее [б о+ л' ь й ь] |
| Б, б (мягкая) | б' | ру**б**ежа [р у б' и ж а+] |
| В, в (твердая) | в | д**в**а [д в а+] |
| В, в (мягкая) | в' | **в**едущих [в' и д у+ щ и х] |
| Г, г (твердая) | г | **г**оворится [г ъ в а р' и+ ц ъ] |
| Г, г (мягкая) | г' | а**г**ентства [а г' е+ н с т в ъ] |
| Д, д (твердая) | д | **д**ва [д в а+] |
| Д, д (мягкая) | д' | **д**еньги [д' е+ н' г' и] |
| Е, е (в ударном слоге) | е+ | д**е**ньги [д' е+ н' г' и] |
| Е, е (в предударном слоге) | и | инв**е**стировать [ы н в' и с' т' и+ р ъ в ъ т'] |
| Е, е (в остальных случаях) | ь | мнени**е** [м н' е+ н' и й ь] |
| Ё, ё (в ударном слоге) | о+ | сч**ё**т [щ о+ т] |
| Ё, ё (в предударном слоге) | и | с**ё**гун [с' и г у+ н] |
| Ё, ё (в остальных случаях) | ь | с**ё**рфингист [с' ь р ф' и н г' и+ с т] |
| Ж, ж | ж | менед**ж**ера [м э+ н ъ д ж ъ р ъ] |
| З, з (твердая) | з | ра**з**витии [р а з в' и+ т' и и] |
| З, з (мягкая) | з' | **з**емлю [з' е+ м л' у] |
| И, и (в ударном слоге) | и+ | пят**и** [п' и т' и+] |
| И, и (в предударном слоге) | и | ф**и**нтех [ф' и н' т' е+ х] |
| И, и (в остальных случаях) | и | деньг**и** [д' е+ н' г' и] |
| Й, й | й | ново**й** [н о+ в ъ й] |
| К, к (твердая) | к | **к**ак [к а+ к] |
| К, к (мягкая) | к' | по**к**идают [п ъ к' и д а+ й у т] |
| Л, л (твердая) | л | работа**л** [р а б о+ т ъ л] |
| Л, л (мягкая) | л' | оплачива**л**и [а п л а+ ч и в ъ л' и] |
| М, м (твердая) | м | **м**нение [м н' е+ н' и й ь] |
| М, м (мягкая) | м' | **м**инут [м' и н у+ т] |
| Н, н (твердая) | н | ми**н**ут [м' и н у+ т] |
| Н, н (мягкая) | н' | де**н**ьги [д' е+ н' г' и] |
| О, о (в ударном слоге) | о+ | раб**о**тал [р а б о+ т ъ л] |
| О, о (в предударном слоге) | а | **о**плачивали [а п л а+ ч и в ъ л' и] |
| О, о (в остальных случаях) | ъ | с**о**средоточатся [с ъ с р' ь д а т о+ ч ь ц ъ] |
| О, о (в безударной позиции без редукции) | о | п**о**эзия [п о э+ з' и й ь] |
| П, п (твердая) | п | **п**оступили [п ъ с т у п' и+ л' и] |
| П, п (мягкая) | п' | **п**яти [п' и т' и+] |
| Р, р (твердая) | р | **р**аботал [р а б о+ т ъ л] |
| Р, р (мягкая) | р' | сос**р**едоточатся [с ъ с р' ь д а т о+ ч ь ц ъ] |
| С, с (твердая) | с | е**с**ли [й е+ с л' и] |
| С, с (мягкая) | с' | обратите**с**ь [а б р а т' и+ т' ь с'] |
| Т, т (твердая) | т | рабо**т**ал [р а б о+ т ъ л] |
| Т, т (мягкая) | т' | пя**т**и [п' и т' и+] |
| У, у (в ударном слоге) | у+ | мин**у**т [м' и н у+ т] |
| У, у (в предударном слоге) | у | ул**у**чшать [у л у ч ш а+ т'] |
| У, у (в остальных случаях) | у | планир**у**ет [п л а н' и+ р у й ь т] |
| Ф, ф (твердая) | ф | штра**ф**ы [ш т р а+ ф ы] |
| Ф, ф (мягкая) | ф' | **ф**интех [ф' и н' т' е+ х] |
| Х, х (твердая) | х | финте**х** [ф' и н' т' е+ х] |
| Х, х (мягкая) | х' | **х**имия [х' и+ м' и й ь] |
| Ц, ц | ц | юсти**ц**ии [й у с' т' и+ ц ы и] |
| Ч, ч | ч | тыся**ч** [т ы+ с' ь ч] |
| Ш, ш | ш | **ш**естом [ш ы с т о+ м] |
| Щ, щ | щ | веду**щ**их [в' и д у+ щ и х] |
| Ы, ы (в ударном слоге) | ы+ | в**ы** [в ы+] |
| Ы, ы (в предударном слоге) | ы | под**ы**грать [п ъ д ы г р а+ т'] |
| Ы, ы (в остальных случаях) | ы | отд**ы**х [о+ д д ы х] |
| Э, э (в ударном слоге) | э+ | **э**тот [э+ т ъ т] |
| Э, э (в предударном слоге) | ы | **э**кстракция [ы к с т р а+ к ц и й ь] |
| Э, э (в остальных случаях) | ъ | А**э**рофлот [а ъ р а ф л о+ т] |
| Э, э (в безударной позиции без редукции) | э | ало**э** [а л о+ э] |
| Ю, ю (в ударном слоге) | у+ | **Ю**ля [й у+ л' ь] |
| Ю, ю (в предударном слоге) | у | вкл**ю**чая [ф к л' у ч а+ й ь] |
| Ю, ю (в остальных случаях) | у | кл**ю**чевых [к л' у ч и в ы+ х] |
| Я, я (в ударном слоге) | а+ | **я**ма [й а+ м ъ] |
| Я, я (в предударном слоге) | и | п**я**ти [п' и т' и+] |
| Я, я (в остальных случаях) | ь | вход**я**т [ф х о+ д' ь т] |

#### Примеры использования SSML-тегов

**<u>Пример 1</u>** (весь текст с SSML-разметкой, отправляемый на синтез, должен быть обернут в тег speak):
```
<speak>Глава 1.
Жаркое лето изменило все планы. Было решено сэкономить на поездке к морю и провести весь отпуск на даче.
«Я уверен вам понравится, поставим бассейн, будем шашлыки жарить» - резюмировал Георгий.
Супруга не разделяла радость: «Я чувствую комары нас съедят».</speak>
```

**<u>Пример 2</u>** (добавляем паузу после «Глава 1.»):
```
<speak>Глава 1. <break time="1.5s"/>
Жаркое лето изменило все планы. Было решено сэкономить на поездке к морю и провести весь отпуск на даче.
«Я уверен вам понравится, поставим бассейн, будем шашлыки жарить» - резюмировал Георгий.
Супруга не разделяла радость: «Я чувствую комары нас съедят».</speak>
```

**<u>Пример 3</u>** (ставим ударение, чтобы Audiogram правильно произнес «жАркое», а не «жаркОе»):
```
<speak>Глава 1. <break time="1.5s"/>
Жа{'}ркое лето изменило все планы. Было решено сэкономить на поездке к морю и провести весь отпуск на даче.
«Я уверен вам понравится, поставим бассейн, будем шашлыки жарить» - резюмировал Георгий.
Супруга не разделяла радость: «Я чувствую комары нас съедят».</speak>
```

**<u>Пример 4</u>** (укажем высоту и скорость произнесения всего текста):
```
<speak speed="0.8" pitch="-0.4">Глава 1. <break time="1.5s"/>
Жа{'}ркое лето изменило все планы. Было решено сэкономить на поездке к морю и провести весь отпуск на даче.
«Я уверен вам понравится, поставим бассейн, будем шашлыки жарить» - резюмировал Георгий.
Супруга не разделяла радость: «Я чувствую комары нас съедят».</speak>
```

**<u>Пример 5</u>** (изменим высоту и скорость произнесения прямой мужской речи):
```
<speak speed="0.8" pitch="-0.4">Глава 1. <break time="1.5s"/>
Жа{'}ркое лето изменило все планы. Было решено сэкономить на поездке к морю и провести весь отпуск на даче.
<prosody speed="1.1" pitch="-0.2">«Я уверен вам понравится, поставим бассейн, будем шашлыки жарить»</prosody> - резюмировал Георгий.
Супруга не разделяла радость: «Я чувствую комары нас съедят».</speak>
```

**<u>Пример 6</u>** (если для синтеза речи используется модель **high_quality**, можно указать какими голосами и эмоциональной окраской озвучить прямую речь):
```
<speak speed="0.8" pitch="-0.4">Глава 1. <break time="1.5s"/>
Жа{'}ркое лето изменило все планы. Было решено сэкономить на поездке к морю и провести весь отпуск на даче.
<prosody speed="1.1" pitch="-0.2"><voice name="gandzhaev" style="happy">«Я уверен вам понравится, поставим бассейн, будем шашлыки жарить»</voice></prosody> - резюмировал Георгий.
Супруга не разделяла радость: <voice name="borisova" style="sad">«Я чувствую комары нас съедят».</voice></speak>
```

## Клонирование голоса

Audiogram поддерживает клонирование голоса. Эта технология используется по запросу абонента для персонализации автоответчика, чтобы научить его разговаривать голосом абонента.

**Внимание!** Голос человека относится к персональным данным. В соответствии с федеральным законом №152-ФЗ "О персональных данных" их сбор и обработка должны осуществляться с согласия субъекта персональных данных в письменной форме на обработку его персональных данных. **Недопустимо** использовать голос человека (как настоящий, так и результат клонирования) в противоправных целях - за это грозит административная и уголовная ответственность.

Клонирование голоса осуществляется следующим образом:

1. В Audiogram отправляется запрос на клонирование голоса. В запросе должны быть аудиофайлы с образцами речи, которую необходимо склонировать.

2. Audiogram создает задачу по клонированию и возвращает ее идентификационный номер.

3. Через некоторое время, используя этот номер, необходимо проверить статус задачи.

4. Если задача выполнена, голос склонирован и готов к использованию. Далее, чтобы озвучить им какой-либо текст, необходимо отправить в Audiogram запрос на синтез речи. В запросе передать текст, который необходимо озвучить, и идентификационный номер голоса для озвучки.

Для клонирования голоса предоставляется gRPC-контракт (.proto-файлы), который можно использовать для создания собственного клиентского приложения:

<u>Основной контракт</u>:

* [voice_cloning.proto](https://github.com/mts-ai/audiogram/blob/main/voice_cloning/v1/voice_cloning.proto) - основной контракт, по которому происходит распознавание речи.

<u>Зависимости</u>:

* [stt_v3.proto](https://github.com/mts-ai/audiogram/blob/main/voice_cloning/v1/stt_v3.proto) - контракт, по которому осуществляется распознавание речи. Описание этого .proto-файла представлено [в секции stt_v3.proto](#stt_v3proto)
* [stt_response.proto](https://github.com/mts-ai/audiogram/blob/main/voice_cloning/v1/stt_response.proto) - конфигурация ответа на запрос на распознавание речи. Описание этого .proto-файла представлено [в секции stt_response.proto](#stt_responseproto)
* [response_header.proto](https://github.com/mts-ai/audiogram/blob/main/voice_cloning/v1/response_header.proto) - структура, содержащая временную метку ответа сервиса; позволяет отследить сетевые задержки. Описание этого .proto-файла представлено [в секции response_header.proto](#response_headerproto)

### voice_cloning.proto

#### Методы

##### CloneVoice

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| CloneVoice | CloneVoiceRequest | TaskId | Метод клонирования голоса. Возвращает идентификационный номер задачи по клонированию голоса. |

##### GetTaskInfo

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| GetTaskInfo | TaskId | TaskInfo | Этот метод позволяет получить текущий статус задачи по клонированию голоса. |

##### DeleteVoice

| Имя метода | Тип запроса | Тип ответа | Описание |
| :--- | :--- | :--- | :--- |
| DeleteVoice | DeleteVoiceRequest | google.protobuf.Empty | Если склонированый голос больше не нужен, этот метод позволяет удалить его из базы. |

#### Сообщения PROTOBUF

##### TaskInfo

Информация о задаче по клонированию голоса.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| voice_id | string | Идентификационный номер склонированного голоса. |
| status | Status | Сообщение типа Status. |

##### Status

Статус задачи по клонированию голоса.

| Имя | Значение | Описание |
| :--- | :--- | :--- |
| UNDEFINED | 0 | Статус задачи не определен. |
| CREATING | 1 | Клонирование голоса в процессе. |
| READY | 2 | Голос склонирован и готов к использованию. |
| ERROR | 3 | Произошла ошибка. |

##### AudioFormat

Формат аудиоданных.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| encoding | mts.ai.audiogram.stt.v3.AudioEncoding | Формат аудиоданных (кодировка). |
| sample_rate_hertz | uint32 | Частота дискретизации аудиоданных в герцах. |
| audio_channel_count | uint32 | Количество каналов во входных аудиоданных. |

##### CloneVoiceRequest

Настройки запроса на клонирование голоса.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| audio_format | AudioFormat | Сообщение типа AudioFormat. |
| signal | bytes | В это поле передается аудио с голосом, который необходимо клонировать. |

##### TaskId

Идентификационный номер задачи по клонированию голоса.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| val | string | Значение идентификационного номера задачи по клонированию голоса. |

##### DeleteVoiceRequest

Настройки запроса на удаление клонированного голоса.

| Поле | Тип | Описание |
| :--- | :--- | :--- |
| voice_id | string | Идентификационный номер голоса, который необходимо удалить из базы. |

## Метаданные gRPC-запросов

* Каждый запрос к Audiogram API должен содержать токен доступа. Передавайте токен следующим способом:
```
authorization: Bearer <access_token>
```
* В запросе можно передать уникальный идентификатор, который позволит детально проследить за историей выполнения запроса. Для этого используйте ключ trace-id:
```
external_trace_id: <id>
```
## Список ML-моделей и голосов в Audiogram

Модель для распознавания речи (**ASR**) или голос для синтеза речи (**TTS**) следует указывать, используя псевдоним (**alias**). Это позволяет обновлять модели без необходимости проводить повторную интеграцию клиентов.

**Внимание!** Если в запросе указана частота дискретизации (sample rate) отличная от значений, поддерживаемых моделью, то:
* в случае распознавания речи (**ASR**) произойдет перекодирование частоты дискретизации на значение, поддерживаемое моделью (16000 Гц).
* в случае синтеза речи (**TTS**) будет использована модель с ближайшей частотой дискретизации в большую сторону.

### ASR e2e

**Alias** – это имя модели, которое указывается в конфиге распознавания **RecognitionConfig.model**

| Alias | Sample rate (Hz) | Описание |
| :--- | :--- | :--- |
| e2e-v3 | 16000 | Модель распознавания речи в файловом и потоковом режимах. |

### TTS

**Alias** – это имя голоса, которое указывается в конфиге распознавания **SynthesizeSpeechRequest.voice_name**

| Alias | Sample rate (Hz) | Описание |
| :--- | :--- | :--- |
| **женские голоса**: |  |  |
| borisova | 8000 | Голос Борисовой 8000 Гц |
| borisova | 22050 | Голос Борисовой 22050 Гц |
| borisova | 44100 | Голос Борисовой 44100 Гц |
| kishchik | 8000 | Голос Кищик 8000 Гц |
| kishchik | 22050 | Голос Кищик 22050 Гц |
| kishchik | 44100 | Голос Кищик 44100 Гц |
| **мужские голоса**: |  |  |
| gandzhaev | 8000 | Голос Ганджаева 8000 Гц |
| gandzhaev | 22050 | Голос Ганджаева 22050 Гц |
| gandzhaev | 44100 | Голос Ганджаева 44100 Гц |
| gavrilov | 8000 | Голос Гаврилова 8000 Гц |
| gavrilov | 22050 | Голос Гаврилова 22050 Гц |
| gavrilov | 44100 | Голос Гаврилова 44100 Гц |

## Сообщения об ошибках

| Код | Описание |
| :--- | :--- |
| PERMISSION_DENIED | Данная ошибка может вернуться в следующих ситуациях:<br> <li>срок действия токена доступа истек;<br> <li>токен недействителен;<br> <li>у клиента нет прав использовать Audiogram (например, клиент заблокирован через консоль администратора);<br> <li>ошибка при попытке авторизации (например, из-за сбоя внутренних сервисов). |
| INTERNAL | Не работают внутренние сервисы |
| UNKNOWN | Ошибки, которые пока не обрабатываются на стороне сервиса |

# Примеры кода клиентских приложений Audiogram

Для работы с Audiogram необходимо создать клиентское приложение. Примеры кода клиентских приложений [собраны в этом разделе](https://github.com/mts-ai/audiogram/tree/main/demo_clients). Их можно использовать в качестве образцов при написании сервисов, использующих Audiogram.

Архив содержит следующие примеры кода:

**Распознавание речи**:

* клиент, выполняющий распознавание речи в файловом режиме
* клиент, выполняющий распознавание речи в потоковом режиме
* клиент, получающий список доступных моделей для распознавания речи

**Синтез речи**:

* клиент, выполняющий синтез речи в файловом режиме
* клиент, выполняющий синтез речи в потоковом режиме
* клиент, получающий список доступных моделей для синтеза речи

**Работа с аудиоархивом**:

* клиент, получающий список запросов на распознавание речи
* клиент, позволяющий скачать аудио, полученное на распознавание речи
* клиент, позволяющий скачать разметку голосовой активности
* клиент, позволяющий скачать результат распознавания речи

**Внимание!** Примеры из архива, перечисленные выше, создавались для [stt_v3.proto](https://github.com/mts-ai/audiogram/blob/main/asr/v3/stt_v3.proto) и [tts_v2.proto](https://github.com/mts-ai/audiogram/blob/main/tts/v2/tts.proto)

В качестве образца кода клиентских приложений для [предыдущей версии stt.proto файла](https://github.com/mts-ai/audiogram/blob/main/asr/v2/stt.proto) используйте следующие примеры:

* [распознавание речи в файловом режиме](https://github.com/mts-ai/audiogram/blob/main/asr/v2/python3/recognize_file.py)
* [распознавание речи в потоковом режиме](https://github.com/mts-ai/audiogram/blob/main/asr/v2/python3/recognize_stream.py)

# История релизов Audiogram

## Текущая версия - Audiogram 3.37.0

Обновление Audiogram 3.37.0 содержит следующие улучшения, исправления и изменения:

**Новые возможности**
* Для улучшения качества синтеза речи добавлен новый SSML-тег `<phoneme>`, который позволяет управлять минимальными единицами языка - фонемами.

**Улучшения**
* Модель антиспуфинга переведена в float16 для увеличения производительности на GPU.
* Проведены доработки в медиа-архиве по части выгрузки аудио и конфигураций.
* Добавлен интонационный DEP.

**Исправления**
* Исправлены ошибки по обрезанию аудио в DEP.
* В компоненте, отвечающем за отложенное распознавание речи, исправлена ошибка с доступом к S3.
* Исправлена ошибка в компоненте punct-denorm, из-за которой при обработке последовательностей чисел в контексте запроса на арифметические действия вырезался союз "и".

**Известные проблемы**
* Аудио не всегда сохраняется в аудиоархиве, ведутся работы по устранению этой ошибки.

## Предыдущие версии

### Audiogram 3.36.2

Audiogram 3.36.2 содержит следующее улучшение:

* В лог-сообщение уровня DEBUG, начинающееся с "Sent message to audio archive", добавлено поле с request_id запроса.

### Audiogram 3.36.1

Audiogram 3.36.1 содержит следующие исправления:

* Исправлена ошибка, из-за которой сумма в рублях с копейками произносилась как дробное число.
* Исправлена ошибка, из-за которой номер телефона произносился как целое число.

### Audiogram 3.36.0

Audiogram 3.36.0 содержит следующие улучшения и исправления:

**Новые возможности**
* Добавлена новая версия модели high_quality со сниженным потреблением ресурсов без ухудшения качества синтеза речи.

**Улучшения**
* Обновлен способ поставки модели распознавания речи e2e-v3 — поддержана возможность развертывания модели на видеокартах A40.
* В балансировщик медиа-архива добавлено дебаг-логирование получаемых в grpc-gateway и отправляемых в receiver данных.
* Добавлены кастомные метрики для tts-server-triton.
* Версия Triton-сервера в компонентах синтеза и распознавания речи обновлена до 24.09 для поддержки кастомных метрик.

**Исправления**
* Исправлена неконсистентность эмоции surprised в теге `<voice>`.
* Исправлена проблема с утечкой памяти в api.

### Audiogram 3.35.1

Audiogram 3.35.1 содержит следующие улучшения и исправления:

**Новые возможности**
* Расширена функциональность SSML-тега `<say-as>`. Теперь с его помощью можно более корректно озвучить номера телефонов, денежные суммы, числа по группам, дроби, десятичные дроби, буквенные значения, которые можно принять за численные, полные даты, а также добавить слово "год" к дате.

**Улучшения**
* В ответы сервиса api добавлены временные метки (timestamps), с помощью которых можно высчитать сетевые задержки.

**Исправления**
* Исправлена ошибка с утечкой памяти компонента speech-segmentation-server.
* Исправлена ошибка, когда "ответ." (с точкой) озвучивалось как "ответственный".

### Audiogram 3.35.0

Audiogram 3.35.0 содержит следующие улучшения:

* Обновлен сервис rate limiter, позволяющий осуществлять лимитирование запросов на различных вариантах инсталляции Audiogram.
* Обновлен сервис api для работы с rate limiter.

### Audiogram 3.34.0

Audiogram 3.34.0 содержит следующие улучшения и изменения:

**Новые возможности**
* Добавлен сервис settings-provider, который позволяет осуществлять синтез и распознавание речи через "пресеты" (заранее сконфигурированные наборы настроек). Это помогает избегать непреднамеренные ошибки в конфигурациях запросов.
* Добавлен сервис rate-limiter. На текущем этапе он позволяет задавать ограничения потребления ресурсов для отдельных кластеров инсталляции Audiogram.

**Улучшения**
* Обновлен сервис antispoofing. Теперь обнаруживаются не только логические атаки (синтезированный голос), но и replay-атаки (заранее записанный "живой" голос).
* Добавлен новый режим VAD - target_speech_VAD. Он позволяет улучшить работу с аудиосигналом — при наличии нескольких источников аудио в одном канале, этот режим должен исключать любые звуки, не являющиеся речью целевого спикера.
* Сервис api обновлен для работы с settings-provider.
* Для балансировщика в медиа-архиве добавлены новые метрики мониторинга.

### Audiogram 3.33.0

Audiogram 3.33.0 содержит следующие улучшения и изменения:

**Новые возможности**
* Добавлены SSML-теги для еще более правильного синтеза речи:
     * тег `<say-as>` (работает только с нормализацией на правилах) для более правильного озвучивания количественных и порядковых числительных, дат и времени.
     * тег `<emphasis>` для более правильного управления интонацией в вопросительных и восклицательных предложениях.
* Добавлена возможность использовать SSML-тег `<date>` с моделью high_quality.

**Улучшения**
* Улучшена нормализация на правилах согласно комментариям пользователей Audiogram.
* В компонент transcriber добавлены наработки по фонетической фразе и ряд исправлений по части ударений и других фонетических аспектов.
* Добавлены новые способы аутентификации для подключения к Kafka.
* Добавлена асинхронная запись в статистику.
* В VAD добавлен новый режим (enhanced_VAD), в котором нарезка аудио производится более точно.
* Оптимизирован прогрев для модели распознавания речи e2e-v1.

**Изменения**
* Нормализатор чисел (numbers) и обработчик сокращений (acronym) объединены в один сервис.
* Прекращена поддержка модели синтеза речи light. Теперь синтез осуществляется только с помощью модели high_quality.

### Audiogram 3.32.0

Audiogram 3.32.0 содержит следующие улучшения и изменения:

**Новые возможности**
* Добавлены две новые модели распознавания речи:
     * модель на базе архитектуры Emformer+Conformer с добавлением TDT (Token-and-Duration Transducer). Название этой модели для обращения в запросах - e2e-v3. Модель имеет встроенный акустический пунктуатор, который работает в файловом, отложенном файловом и потоковом режимах распознавания речи.
     **Примечание:** пользователям Audiogram рекомендуется тестировать эту модель, так как она показывает наименьший WER (Word Error Rate) среди других моделей для распознавания речи.
     * модель на базе архитектуры Emformer+Conformer. Название этой модели для обращения в запросах - e2e-v2. Также имеет встроенный акустический пунктуатор.

**Изменения**
* Внесены изменения в компонент asr-e2e-agent с целью поддержки новых моделей распознавания речи и новых режимов VAD, которые будут представлены в следующих обновлениях.
* Обновлены сервисы аутентификации пользователей на базе IAM с целью поддержки новых моделей распознавания речи.

### Audiogram 3.31.0

Audiogram 3.31.0 содержит следующие улучшения и исправления:

**Новый функционал**
* В компоненте asr-e2e-agent:
     * добавлена возможность проверять состояние соединений с помощью механизма KEEPALIVE.
     * добавлена возможность принимать и устанавливать защищенное соединение.

**Улучшения**
* Добавлена метрика real_time_lag, которая показывает есть ли задержки во время потокового распознавания речи. Это позволит вовремя обнаружить возможные проблемы с производительностью.
* Часть логов информативного характера (например, финальные расшифровки речи) вынесены с уровня DEBUG на уровень INFO, что позволит извлекать логи в тех случаях, когда нет параметра request_id.
* В целях устранения уязвимостей в asr-e2e-agent выровнены версии базового образа и зависимых Python-библиотек.

**Исправления**
* Исправлена ошибка потокового распознавания речи, которая появлялась при включении режима отправки разметки VAD va_response_mode=VA_ENABLE.

### Audiogram 3.30.0

Audiogram 3.30.0 содержит следующее улучшение:
* Внесены различные изменения, повышающие стабильность работы компонентов, отвечающих за асинхронное (отложенное) распознавание.

### Audiogram 3.29.0

Audiogram 3.29.0 содержит следующие улучшения и исправления:

**Новый функционал**
* Добавлена возможность настраивать через переменную окружения компонента audio-archive-back к какому бакету хранилища extremum будет обращаться Audiogram. Это упрощает настройку окружений, когда у вас несколько стендов с Audiogram.
* На всех микросервисах, вошедших в это обновление Audiogram, добавлена возможность проверять состояние соединений с помощью механизма KEEPALIVE.

**Улучшения**
* В асинхронное (отложенное) распознавание речи добавлена более оптимальная модель VAD (Voice Activity Detection), что позволит увеличить пропускную способность и распознавать файлы больших размеров.
* Повышена стабильность функционирования ML-модели, отвечающей за диаризацию (разделение) спикеров, на GPU.
* В целях оптимизации часть логов с уровня INFO была перенесена на уровень DEBUG.

**Исправления**
* Исправлена ошибка, которая возникала из-за того, что Triton-server и ML-модель одновременно использовали порт 8003.
* Исправлена проблема с утечкой памяти в интерфейсе offline_vad, который используется для диаризации спикеров, посредством перевода работы offline_vad с CPU на GPU.

### Audiogram 3.28.0

Audiogram 3.28.0 содержит следующее улучшение:

* Осуществлен переход на групповую (батчевую) обработку запросов между компонентами для синтеза речи tts-agent и tts-server. Это позволит минимизировать сетевые задержки и затраты на передачу служебной информации.
Алгоритм группировки запросов работает без таймаута, что делает его более приемлемым для непрерывной большой нагрузки.
Размер группы (по умолчанию 5 запросов) настраивается на стороне tts-agent через переменную TTS_AGENT_TTS_BATCH_SIZE.

### Audiogram 3.27.0

Audiogram 3.27.0 содержит следующие улучшения и изменения:

**Новый функционал**
* Внедрена поддержка отложенного распознавания речи. Этот функционал позволяет распознавать файлы размером до 1 ГБ за период до 8 часов.

**Улучшения**
* Обновлена модель синтеза речи high_quality. В ней выровнен интонационный рисунок на "склейках" (местах соединения фрагментов озвучивания) и улучшено качество синтеза в целом. Также модель теперь потребляет столько же ресурсов, сколько и менее ресурсоемкая модель light, при той же пропускной способности и том же уровне latency.

**Изменения**
* Начиная с этого обновления, вступают в силу следующие изменения:
     * Audiogram API поддерживает транскодер только версии 2.0 и выше.
     * tts-agent больше не поддерживает модель синтеза light. Для вызова модели light необходимо использовать tts-agent версии 7.1.z.
     * Протокол взаимодействия с сервисами transcriber, acronym и numbers изменен с HTTP на gRPC.

### Audiogram 3.26.0

Audiogram 3.26.0 содержит следующее улучшение:
* Реализована поддержка шифрования данных, сохраняемых в аудиоархив, и возможность их дешифровки на стороне компонента archive-back. Это позволило повысить уровень безопасности для коммуникации между архивом и другими сервисами Audiogram, а также надежнее защитить данные в архиве от потенциальных угроз.

### Audiogram 3.25.0

Audiogram 3.25.0 содержит следующие улучшения и исправления:
* Скорость модели антиспуфинга повышена в ~2 раза с улучшением качества работы.
* Модели пунктуатора и денормализатора чисел оптимизированы и объединены в один Triton-сервер без потери обратной совместимости, что позволило повысить уровень RPS и снизить latency.
* Улучшено качество работы модели денормализатора чисел (особое внимание было уделено обработке номеров карт, лицевых счетов, серии/номера паспорта, а также почтовых индексов):
     * Исправлена ошибка, из-за которой денормализатор не обрабатывал числа, написанные с большой буквы.
     * Исправлена ошибка, из-за которой в распознавании длинных последовательностей цифр, продиктованных по одной цифре, могли появиться лишние элементы.
     * Исправлена ошибка, из-за которой денормализатор не обрабатывал числительные, в названии которых присутствовала буква "ё".

### Audiogram 3.24.0

Audiogram 3.24.0 содержит следующие улучшения и исправления:
* Улучшена ML-модель "Денормализатор чисел":
     * Triton-сервер обновлен до версии 24.05.
     * Добавлены 2 вида config-файлов - для CPU- и GPU-версий.
     * При выборе работы модели на GPU теперь все вычисления максимально переносятся на видеокарту. Это уменьшает потребление CPU-ядер и несколько ускоряет работу на видеокарте.
* Улучшена ML-модель "Обработчик сокращений":
     * Исправлен ряд ошибок, которые приводили к некорректной озвучке некоторых сокращений.
     * Расширен датасет с "руб." и "коп." для более корректной озвучки этих сокращений.
* Исправлена ошибка записи результатов распознавания речи в случаях мгновенного закрытия канала после отправки данных со стороны клиента.

### Audiogram 3.23.0

Audiogram 3.23.0 содержит следующие улучшения:
* Исправлена ошибка, из-за которой паузы между словами при синтезе речи были длиннее, чем указывалось в ssml-разметке.
* Исправлена ошибка, из-за которой первые запросы на синтез речи в "непрогретую" ML-модель завершались падением.

### Audiogram 3.22.1

В обновлении Audiogram 3.22.1 оптимизирована логика передачи client_id (необходим для получения данных из s3) в Audiogram API для записи в хранилище s3.

Если при работе с Audiogram используется авторизация, client_id не нужно передавать в запросе - Audiogram api сделает это автоматически.

Если работа с Audiogram проходит без авторизации, client_id необходимо передавать в заголовке запроса в виде пары ключ-значение.

### Audiogram 3.22.0

Audiogram 3.22.0 содержит следующие обновления и улучшения:

**Новый функционал**

* Добавлен сервис, который в распознанной речи осуществляет денормализацию чисел (преобразует текстовое представление числа в цифровое, например, "пять файлов > 5 файлов").
* Добавлен сервис, который в распознанной речи проводит капитализацию необходимых слов и расставляет знаки препинания (точка, запятая, вопросительный знак, дефис).
* Добавлен сервис, который осуществляет диаризацию речи во время распознавания (разделяет входящий аудиопоток на однородные сегменты в соответствии с их принадлежностью тому или иному говорящему).

**Улучшения**

* В ответе на запрос списка моделей распознавания речи теперь содержатся имена WFST графов, интегрированных в модели.
* Обновлены дашборды для Triton-серверов.
* Обновлён дашборд для сервиса api.
* Исправлены разного рода уязвимости (в частности, добавлены последние версии различных библиотек).

### Audiogram 3.21.0

Audiogram 3.21.0 содержит следующие обновления, улучшения и исправления:

* В Audiogram API добавлена поддержка публичного stt_v3.proto и сохранена обратная совместимость с stt_v2.proto.
* Выполнен переход на stt_v3.proto во всех сервисах модулей ASR и MEDIA.
* Проведена подготовка по добавлению нового сервиса денормализации чисел (преобразует текстовое представление числа в цифровое, например, "пять файлов > 5 файлов").
* Проведена подготовка по добавлению нового сервиса, который в распознанной речи проводит капитализацию необходимых слов и расставляет знаки препинания (точка, запятая, вопросительный знак, дефис).
* Добавлена возможность оперативно улучшать результаты распознавания речи с помощью технологии WFST графов. Заказчик предоставляет список терминов, распознавание которых необходимо улучшить. На основе списка создается WFST граф и интегрируется в модель распознавания речи. После этого модель будет распознавать слова из списка более точно.
* Исправлены разного рода уязвимости (в частности, добавлены последние версии различных библиотек).
* Улучшено качество распознавания англицизмов с помощью модели e2e-enru (данная модель распознает англицизмы английскими словами).

### Audiogram 3.20.0

Audiogram 3.20.0 содержит следующие улучшения:

**Исправление ошибок**

* Исправлена ошибка, которая иногда возникала при подготовке текста на озвучку и приводила к появлению искажений в конечном звучании.

### Audiogram 3.19.0

Audiogram 3.19.0 содержит следующие улучшения и исправления:

**Улучшения**

* Информация о client_id (для api) перенесена с уровня debug-логов на уровень info с целью реализации возможности собирать данные по запросам от разных клиентов.

**Исправление ошибок**

* Исправлена ошибка синтеза речи, из-за которой символ тире "-" в некоторых случаях озвучивался как "минус".
* Исправлена ошибка, из-за которой некорректно озвучивались структуры типа "0.01 руб.".
* Исправлена ошибка, из-за которой некорректно озвучивались фразы, оканчивающиеся на сокращение, сразу за которым следовал SSML-тег (например, `... 562.0 руб.</speak>`).

### Audiogram 3.18.0

Audiogram 3.18.0 содержит следующие улучшения и исправления:

**Улучшения**

* Повышена скорость работы Triton-серверов с ML-моделями на CPU.
* Повышена скорость записи аудиоданных, поступивших на распознавание, и результатов расшифровки в архив (Extremum).
* Добавлена балансировка по весам для antispoofing-agent.
* Реализована поддержка масштабируемости и наблюдаемости сервиса antispoofing-agent, а также создан дашборд для Grafana.

**Исправление ошибок**

* Исправлена редкая ошибка, из-за которой случались искажения в распознавании речи при отправке чанков аудио нечетного размера.
* Исправлена ошибка, из-за которой при детекции речи через DEP в редких случаях могла дублироваться метка BEGIN, что приводило к прерыванию выполнения запроса.

### Audiogram 3.17.0

Audiogram 3.17.0 содержит следующие улучшения, обновления и исправления:

**Новый функционал**

* Добавлена возможность передавать новый ключ session-id в метаданных запросов на распознавание речи. По этому ключу можно агрегировать из аудиоархива все запросы, относящиеся к одному диалогу.

**Улучшения**

* Обновлена модель high_quality: произведено ускорение тритон-сервера, улучшен интонационный рисунок синтеза.

**Исправление ошибок**

* Исправлена ошибка, которая приводила к погрешностям при сборе статистики по синтезу и распознаванию речи.
* Исправлена ошибка, из-за которой количество каналов в многоканальных аудио не изменялось на 1 при значении параметра split_by_channels = False, что приводило к ошибкам и сбоям в работе транскодера.

### Audiogram 3.16.0

Audiogram 3.16.0 содержит следующие улучшения, обновления и исправления: 

**Новый функционал**

* Добавлен новый сервис Антиспуфинг, позволяющий отличить реального человека от бота при входящем звонке.

**Улучшения**

* Произведен рефакторинг компонента asr-e2e-agent.

**Исправление ошибок**

* Исправлена ошибка, из-за которой для некоторых аудио, отправленных на распознавание в потоковом режиме с выключенным VAD, приходили пустые результаты распознавания.

### Audiogram 3.15.0

Audiogram 3.15.0 содержит следующие улучшения и исправления:

**Оптимизация**

* Ускорена ML-нормализация чисел более, чем в 2 раза, за счёт изменения алгоритмов работы.

**Исправление ошибок**

* Исправлена ошибка, из-за которой иногда происходила некорректная озвучка дат и сумм в некоторых падежах.

### Audiogram 3.14.0

Audiogram 3.14.0 содержит следующие улучшения:

**Новый функционал**

* Добавлена поддержка определения тональности аудио при распознавании речи. По тону высказывание может быть позитивным, нейтральным, грустным или сердитым.<br/>
Определение тональности работает по сегментам VAD (Voice Activity Detection). Если VAD выключен, определяется тональность всего аудио. Если VAD включен, то определяется тональность каждого сегмента, отмеченного VAD.

**Оптимизация**

* Проведены работы по общей оптимизации Audiogram, направленные на повышение быстродействия сервиса и уменьшение потребления системных ресурсов:
  * Библиотека log-kit была дополнительно переработана и обновлена в следующих сервисах:
    * **api**
    * **asr-e2e-agent**
    * **tts-agent**
    * **vad-agent**
    * **genderage-agent**
    * **statistics-api**
    * **statistics-ingester**
    * **grpc-service-template**
  * Сервисы Audiogram, работающие по gRPC, переведены на формат пропагации трассировки ABNF.
  * Оптимизирована упаковка чанков аудио в InferInput.
  * Удалена метка **grpc-code** для метрики **grpc_requests_processing_time_seconds**.<br/>

  Результаты оптимизации по сравнению с предыдущей версией Audiogram:<br/>

  <u>Распознавание речи (ASR)</u>:
  * 100 одновременных запросов в потоковом режиме - Latency p95 сократился на 8%; Latency mean сократился на 11%
  * 150 одновременных запросов в потоковом режиме - Latency p95 сократился на 17.4%; Latency mean сократился на 29.8%
  * 100 одновременных запросов в файловом режиме - RTFx увеличился на 7%
  * 150 одновременных запросов в файловом режиме - RTFx увеличился на 6.1%

  <u>Синтез речи (TTS) (проверялся только потоковый режим; замеры по файловому режиму отдельно не проводились, так как он основан на потоковом)</u>:
  * 100 одновременных запросов на синтез в потоковом режиме моделью light - Latency p95 сократился на 4.5%; Latency mean сократился на 3%; RTFx увеличился на 7.5%
  * 100 одновременных запросов на синтез в потоковом режиме моделью high_quality - Latency p95 сократился на 4.2%; Latency mean сократился на 6%; RTFx увеличился на 5.8%

* Проведены доработки сервиса **transcriber**:
  * Triton Inference Server обновлен до версии 23.07.
  * С целью улучшения качества синтеза речи пополнены следующие словари:
    * эфикация
    * ёфикация
    * однозначные ударения
    * морфологические омонимы
    * контекстуальные омонимы
    * слова с дефисом

* Проведены доработки и интеграция обновленного сервиса **transcoder**:
  * Изменен способ задания формата кодеков. Теперь приходящий в api запрос имеет следующий маппинг по полю encoding сообщения AudioEncoding:<br/>
    <table>
    <tr><th>AudioEncoding</th><th>Значение поля format</th><th>Значение поля codec</th></tr>
    <tr><td>ENCODING_UNSPECIFIED</td><td>не поддерживается</td><td>не поддерживается</td></tr>
    <tr><td>LINEAR_PCM</td><td>s16le</td><td>s16le</td></tr>
    <tr><td>FLAC</td><td>не поддерживается</td><td>не поддерживается</td></tr>
    <tr><td>MULAW</td><td>s16le</td><td>pcm_mulaw</td></tr>
    <tr><td>ALAW</td><td>s16le</td><td>pcm_alaw</td></tr>
    </table><br/>

  * Передача трассировочной информации теперь осуществляется через метаданные в формате ABNF.
  * Добавлена поддержка версионирования api и обратная совместимость между версиями сервиса **transcoder**.
  * Проведена прямая интеграция библиотек FFmpeg в **transcoder**, что позволило увеличить пропускную способность сервиса в 10-15 раз.

* Повышена точность работы сервиса **genderage** за счет изменения значения CHUNK_ALIGNMENT_SIZE по умолчанию с 25600 до 32000 секунд.

**Исправление ошибок**

* Исправлена ошибка, из-за которой распознавание в файловом режиме проходило успешно, но в логах сервиса **asr-e2e-agent** иногда записывалась ложная ошибка о незакрытой последовательности контекста.
* Исправлена ошибка, из-за которой при запросе доступных ML-моделей в список попадали более не поддерживаемые модели.
* Исправлена ошибка, из-за которой клиентское приложение зависало при отправке в сервис **genderage** нечетного количества байт.
* Исправлена ошибка, из-за которой в запросах от **api** к **transcoder** иногда выставлялось неверное значение аудиоканалов.

### Audiogram 3.10.0

Audiogram 3.10.0 содержит следующие улучшения:

**Новый функционал**

* Добавлена поддержка обработки сокращений и ML-нормализации чисел (с сохранением функционала нормализации чисел, работающей на правилах).
* Добавлена поддержка распознавания многоканального аудио (каждый канал распознаётся по отдельности).

**Оптимизация**

* Улучшена работа библиотеки log-kit, что позволит сервисам Audiogram тратить меньше времени и ресурсов на запись логов.

**Исправление ошибок**

* Исправлена ошибка в работе сервиса DEP, из-за которой в некоторых случаях, когда голос звучал в самом начале первого чанка, некорректно идентифицировалось начало речи.
* Исправлена ошибка в работе сервиса VAD, из-за которой иногда некорректно выставлялись метки начала и конца речи.

### Audiogram 3.9.0

В обновлении Audiogram 3.9.0 вдвое увеличена скорость синтеза речи моделью high_quality.

### Audiogram 3.8.0

Audiogram 3.8.0 содержит следующие улучшения:

**Оптимизация**

* Переработана и оптимизирована трассировка для компонентов **asr-e2e-agent** и **vad-agent**, что позволило сократить задержку (latency) p99.

* Переработано и оптимизировано логирование для компонента **asr-e2e-agent**, что позволило сократить задержку и нагрузку на систему.

* Проведены исследования и увеличена длительность аудиофрагмента, отправляемого на расшифровку, с 0.8 до 2 секунд. Это позволило снизить нагрузку на систему и количество ошибок распознавания речи (WER - Word Error Rate).

* Упрощено извлечение информации из логов за счет введения структурированного логирования для компонентов **auth** и **audio-archive-back**.

**Исправление ошибок**

* Исправлена ошибка, из-за которой в логах сборки обфусцированных образов **asr-e2e-agent**, **vad-agent** и **audio-archive-back** появлялась строка о проблеме, но при этом сами образы были рабочими.

* Исправлена ошибка, из-за которой метрики производительности компонента **vad-agent** не отображались на обзорной панели.

* Исправлена ошибка, из-за которой в ключе tts-cache не учитывалось применение постобработки, вследствие чего один и тот же текст нельзя было озвучить с другим видом постобработки.

* Исправлена ошибка, из-за которой наблюдалось снижение производительности синтеза речи при включенной авторизации.

* Исправлена ошибка, из-за которой в ответе на запрос распознанных фраз из архива **audio-archive-back** возвращал только первую фразу.

**Дополнительно**

* Версия Triton в VAD обновлена до 23.07 для более стабильной работы сервиса.

* Для избежания проблем с уязвимостью обновлена версия утилиты grpc_health_probe до 0.7.0.

* Обновлён образ **audio-archive-back** (Python > v3.11). 

### Audiogram 3.7.0

Audiogram 3.7.0 содержит следующие улучшения:

**Новый функционал:**

* Добавлены gRPC-метрики, позволяющие отслеживать взаимодействие между компонентами **asr-e2e-agent** и **genderage_agent** (количество запросов, количество запросов в прогрессе, время выполнения запросов, количество ошибок и т.д.) с помощью Prometheus.

* Реализована возможность работы сервиса **genderage** отдельно от встроенного **VAD** (Voice Activity Detection), что позволяет заказчикам при необходимости подключать свой собственный VAD (компонент, отвечающий за определение голосовой активности в аудио).

**Оптимизация**

* Фразы, полученные при распознавании в файловом режиме, больше не объединяются в один элемент, а перечисляются по отдельности. Это позволяет впоследствии корректно выполнить определение пола и возраста участников разговора, если в аудио несколько спикеров.

* Повышена скорость взаимодействия **asr-e2e-agent** и Triton-сервера благодаря оптимизации подготовки инпутов (объектов для входа). 

**Исправление ошибок**

* Исправлена ошибка с отправкой некорректной метки, из-за которой в Prometheus не отображались алерты (alerts) для компонента **asr-e2e-agent**.

* Исправлена ошибка с отправкой некорректной метки, из-за которой в Prometheus не отображались алерты (alerts) для компонента **vad-agent**.

* Исправлена ошибка, из-за которой возникали разные результаты определения пола при отправке запроса к **genderage** через Audiogram API и напрямую.

* Исправлена ошибка, из-за которой распознавание речи не работало при выключенном **VAD**.

### Audiogram 3.6.0

Audiogram 3.6.0 содержит следующие улучшения:
1. В ходе тестирования были выявлены и исправлены несколько ошибок, что повысило общую стабильность работы сервиса.

2. Оптимизированы развертывание, работа и названия моделей для синтеза речи. Теперь обе модели доступны одновременно. Чтобы выбрать какой моделью необходимо произвести озвучку, передайте её название в запросе:
    * **light** - эта модель является менее ресурсоемкой и рекомендуется к использованию в производственных целях.
    * **high_quality** - данная модель потребляет больше системных ресурсов, так как относится к новому поколению моделей, отличающихся более хорошими показателями качества синтеза, На данный момент ее рекомендуется использовать при невысокой нагрузке.

    Вы можете выбрать любую модель, но если в запросе не указать конкретное название, то для синтеза в потоковом режиме по умолчанию будет использоваться **light**, а для синтеза в файловом режиме - **high_quality**.

### Audiogram 3.5.1

Audiogram 3.5.1 содержит следующее улучшение:
1. Исправлена ошибка трассировки, из-за которой в один трейс попадали спаны нескольких запросов.

### Audiogram 3.5.0

Audiogram 3.5.0 содержит следующие улучшения:

**Для сервиса распознавания речи (ASR)**

1. Проведены работы по снижению задержки (latency). Например: убрано шифрование модуля sentence-piece (данное изменение не влияет на безопасность); внедрен новый предиктор ML-модели; и др.

**Для сервиса синтеза речи**

1. Внедрена новая модель, что привело к улучшению интонаций и уменьшению количества потребляемых ресурсов видеокарты.
2. Улучшено качество синтеза голоса Ганджаева благодаря дополнительному обучению моделей.